\section{Design}
\label{chapter:Design}

In this section, we cover the design of \textsc{TypeShield}. 
First, we present the theory and definitions for our instructions analysis based on register states in~\cref{section:instructionanalysis}. 
Second, we present the details of our new \emph{type} policy in~\cref{section:typepolicy}. 
Finally, we present the design of our calltarget analysis in~\cref{section:calltargetanalysis} and the design of our 
callsite analysis in~\cref{section:callsiteanalysis}.

\subsection{Analysis of Register-States}
\label{section:instructionanalysis}
Instead of symbol based data-flow analysis, our approach is register state based. Therefore, we need to adapt the usual definitions.
The set $\texttt{INSTR}$ describes all possible instructions that can occur within the executable section of a binary. In our case,
this is based on the instruction set for x86-64 processors.
An instruction $i \in \texttt{INSTR}$ can non-exclusively perform two kinds of operations on any number of existing 
registers:\footnote{There are registers that can directly access the higher 
8-bit of the lower 16-bit. For our purpose we register this access as a 16-bit access.}
\textit{1)} read $n$-bit from the register with $n \in \{ 64, 32, 16, 8 \}$, and 
\textit{2)} write $n$-bit to the register with $n \in \{ 64, 32, 16, 8 \}$.
We descibe the possible change within one register 
as $\delta \in \Delta$ with $\Delta = \{ w64, w32, w16, w8, 0 \} \times \{r64, r32, r16, r8, 0 \}$. \footnote{Note that 0 signals the absence
of either a write or read access and $(0, 0)$ signals the absence of both. Furthermore, $wn$ or $rn$ with $n \in \{64,32,16,8\}$ implies all $wm$ or $rm$ 
with $m \in \{64,32,16,8\}$ and $m < n$ (\textit{e.g.,} $r64$ implies $r32$). Note that we exclude 0, as it means the absence of any access.}
SystemV ABI specifies 16 general purpose integer registers. Therefore, we represent the change occurring at the processor level as $\delta_p \in \Delta^{16}$. 
We calculate this change for each instruction $i \in \texttt{INSTR}$ via the function $decode : \texttt{INSTR} \mapsto \Delta^{16}$.

% Finally, in \cref{section:addresstakenanalysis} we introduce a version of 
% address taken analysis based on \cite{mingwei:sekar} to restrict the number of available calltargets even more. 
%At last we introduce a patching schema for callsites and calltargets to enforce the invariants we inferred.

%Usually data-flow analysis algorithms are based on set of variable or sets of definitions, which both are basically unbounded. However, we are analyzing the state of registers, which are baked into hardware and therefore their number is given, thus requiring us to adapt the data-flow theory to work on tuples.
%
%The set $\mathcal{I}$ describes all possible instructions that can occur within the executable section of a binary. In our case this is based on the instruction set for x86-64 processors.
%
%An instruction $i \in \mathcal{I}$ can non-exclusively perform two kinds of operations on any number of existing registers:
%\textit{1)} Read $n$-bit from the register with $n \in \{ 64, 32, 16, 8 \}$, and
%\textit{2)} Write $n$-bit to the register with $n \in \{ 64, 32, 16, 8 \}$.
%
%Thus, we describe the possible change that occurs in one register with the set $S = \{ w64, w32, w16, w8, 0 \} \times \{r64, r32, r16, r8, 0 \}$. Note that 0 signals the absence of either a write or read access and $(0, 0)$ signals the absence of both. Furthermore, $wn$ or $rn$ with $n \in \{64,32,16,8\}$ implies all $wm$ or $rm$ with $m \in \{64,32,16,8\}$ and $m < n$ (\textit{e.g.,} $r64$ implies $r32$). Note that we exclude 0, as it means the absence of any access.

%SystemV ABI specifies 16 general purpose integer registers, thus for our purpose we represent the change occurring at the processor level as $\mathcal{S} = S^{16}$.

%At last we declare a function, which calculates the change occurring in the processor state, when executing an instruction from $\mathcal{I}$:
%$decode : \mathcal{I} \mapsto \mathcal{S}$.

%However, we do not go into detail how this function actually calculates this sate, because we rely on external libraries to perform this task. Implementing this function our self is out of scope due to the lengthy work required, as the x86-64 instruction set is quite large.


\subsection{\emph{Type} Policy}
\label{section:typepolicy}
\begin{figure}[!h]
\center
\resizebox{\columnwidth}{!}{
\begin{tikzpicture}

\fill[black!10!white] (0,7.5) rectangle (12,6);
\fill[black!20!white] (0,6) rectangle (12,4.5);
\fill[black!30!white] (0,4.5) rectangle (12,3);
\fill[black!40!white] (0,3) rectangle (12,1.5);
\fill[black!50!white] (0,1.5) rectangle (12,0);

\draw[-triangle 45, thick] (-0.5,0) -- node[sloped, anchor=center, above] {\Huge{growing required bits/parameter}} (-0.5,7.5);
\draw[-triangle 45, thick] (12.5,7.5) -- node[sloped, anchor=center, above] {\Huge{growing provided bits/parameter}} (12.5,0);

\draw (0,7.5)  --node[anchor=south] {\rot{\Huge{param 6}}} (2,7.5);
\draw (2,7.5)  --node[anchor=south] {\rot{\Huge{param 5}}} (4,7.5);
\draw (4,7.5)  --node[anchor=south] {\rot{\Huge{param 4}}} (6,7.5);
\draw (6,7.5)  --node[anchor=south] {\rot{\Huge{param 3}}} (8,7.5);
\draw (8,7.5)  --node[anchor=south] {\rot{\Huge{param 2}}} (10,7.5);
\draw (10,7.5) --node[anchor=south] {\rot{\Huge{param 1}}} (12,7.5);

\draw (0,7.5)  rectangle node[anchor=center] {\Huge{0-bits}} (2,6);
\draw (2,7.5)  rectangle node[anchor=center] {\Huge{0-bits}} (4,6);
\draw (4,7.5)  rectangle node[anchor=center] {\Huge{0-bits}} (6,6);
\draw (6,7.5)  rectangle node[anchor=center] {\Huge{0-bits}} (8,6);
\draw (8,7.5)  rectangle node[anchor=center] {\Huge{0-bits}} (10,6);
\draw (10,7.5) rectangle node[anchor=center] {\Huge{0-bits}} (12,6);

\draw (0,6)  rectangle node[anchor=center] {\Huge{8-bits}} (2,4.5);
\draw (2,6)  rectangle node[anchor=center] {\Huge{8-bits}} (4,4.5);
\draw (4,6)  rectangle node[anchor=center] {\Huge{8-bits}} (6,4.5);
\draw (6,6)  rectangle node[anchor=center] {\Huge{8-bits}} (8,4.5);
\draw (8,6)  rectangle node[anchor=center] {\Huge{8-bits}} (10,4.5);
\draw (10,6) rectangle node[anchor=center] {\Huge{8-bits}} (12,4.5);

\draw (0,4.5)  rectangle node[anchor=center] {\Huge{16-bits}} (2,3);
\draw (2,4.5)  rectangle node[anchor=center] {\Huge{16-bits}} (4,3);
\draw (4,4.5)  rectangle node[anchor=center] {\Huge{16-bits}} (6,3);
\draw (6,4.5)  rectangle node[anchor=center] {\Huge{16-bits}} (8,3);
\draw (8,4.5)  rectangle node[anchor=center] {\Huge{16-bits}} (10,3);
\draw (10,4.5) rectangle node[anchor=center] {\Huge{16-bits}} (12,3);

\draw (0,3)  rectangle node[anchor=center] {\Huge{32-bits}} (2,1.5);
\draw (2,3)  rectangle node[anchor=center] {\Huge{32-bits}} (4,1.5);
\draw (4,3)  rectangle node[anchor=center] {\Huge{32-bits}} (6,1.5);
\draw (6,3)  rectangle node[anchor=center] {\Huge{32-bits}} (8,1.5);
\draw (8,3)  rectangle node[anchor=center] {\Huge{32-bits}} (10,1.5);
\draw (10,3) rectangle node[anchor=center] {\Huge{32-bits}} (12,1.5);

\draw (0,1.5)  rectangle node[anchor=center] {\Huge{64-bits}} (2,0);
\draw (2,1.5)  rectangle node[anchor=center] {\Huge{64-bits}} (4,0);
\draw (4,1.5)  rectangle node[anchor=center] {\Huge{64-bits}} (6,0);
\draw (6,1.5)  rectangle node[anchor=center] {\Huge{64-bits}} (8,0);
\draw (8,1.5)  rectangle node[anchor=center] {\Huge{64-bits}} (10,0);
\draw (10,1.5) rectangle node[anchor=center] {\Huge{64-bits}} (12,0);
\end{tikzpicture}
}
\caption{The \emph{type} policy schema for callsites and calltargets. As is demonstrated here, when requiring wideness, one starts at the bottom and grows to the 
top, as it is always possible to accept more than one requires. The reverse is true for providing, as it is possible to accept less than provided.}
\label{fig:TYPEschema}
\end{figure}
As shown in Figure \ref{fig:TYPEschema}, our idea is to not simply classify callsites and calltargets based on the number of parameters they provide or 
request, but also on the parameter type. To simplify our approach we use the wideness of the type and do not infer the actual type.
As previously mentioned, there are 4 types of reading and writing accesses. Therefore, our set of possible types for parameters is $\texttt{TYPE} = \{64, 32, 16, 8, 0\}$; 
where 0 models the absence of a parameter. Since SystemV ABI specifies 6 registers as parameter holding 
registers, we classify our callsites and calltargets into $\texttt{TYPE}^6$.
Similar to the policy of \texttt{TypeArmour}, we allow overestimations of callsites and underestimations of calltargets, however on the level of types. Therefore, for a 
callsite $cs$ it is possible to call a calltarget $ct$, only if for each parameter of $ct$ the corresponding parameter of $cs$ is not smaller w.r.t. the wideness.
This results in a finer-grained policy further restricting the possible pool of calltargets for each callsite.

%What we call the \emph{type} policy is the idea of not only relying on the parameter count but also on the parameter type. However, due to complexity reasons,
%we are restricting ourselves to the general purpose registers, which the SystemV ABI designates as parameter registers. Furthermore, we are not inferring 
%the actual type of the data but the wideness of the data stored in the register. The schema again is that we have calltargets requiring wideness and the
%callsite providing it as depicted in Figure \ref{fig:TYPEschema}.

%e are currently interested in x86-64 binaries, the registers we are looking at are 64-bit registers that can be accessed in four different ways:
%\textit{1)} the whole 64-bit of the register, meaning a wideness of 64,
%\textit{2)} the lower 32-bit of the register, meaning a wideness of 32,
%\textit{3)} the lower 16-bit of the register, meaning a wideness of 16, and
%\textit{4)} the lower 8-bit of the register, meaning a wideness of 8.

%Four of those registers can also directly access the higher 8-bit of the lower 16-bit of the register. For our purpose we register this access as a 16-bit access. 

%Based on this information,we can assign a register one of 5 possible types $\mathcal{T} = \{64, 32, 16, 8, 0\}$. We also included the type 0 to model the absence of data within a register. 
%Similar to the \emph{count} policy, we allow overestimation of types in callsites and underestimation of types in calltargets. However, the matching idea is different, 
%because as can we depict in Figure \ref{fig:TYPEschema}, the type of a calltarget and a callsite no longer depends solely on its parameter count, 
%each callsite and calltarget has its type from the set of $\mathcal{T}^6$, with the following comparison operator:
%$
%	u \leq_{type} v :\Longleftrightarrow  
%	\forall_{i = 0}^{5} {u_i \leq v_i} , \text {with } u, v \in \mathcal{T}^6
%$.

%Again we allow any callsite $cs$ call any calltarget $ct$, when it fulfills the requirement $ct \leq cs$. 
%The way we represent this is by letting the type for a calltarget parameter progress from 64-bit to 0-bit---if a calltarget requires a 32-bit value in its 1st parameter, it also should accept a 64-bit value from its callsite---and similarly we let the type for a callsite progress from 0-bit to 64-bit - If a callsite provides a 32-bit value in its 1st parameter it also provides a 16-bit, 8-bit and 0-bit to a calltarget. Now the advantage of the \emph{type} policy in comparison to the \emph{count} policy is that while our type comparison implies the count comparison, the other direction does not hold.
%Meaning, just having an equal or lesser number of parameters than a callsite, does no longer allow a calltarget being called there, thus restricting the number of calltargets per 
%callsite even further. A function that requires 64-bit in its first parameter, and 0-bit in all other parameters, would have been callable by a callsite providing 8-bit 
%in its first and second parameter when using the \emph{count} policy, however in the \emph{type} policy this is no longer possible. Thus, it should decrease the number of targets per bucket.


    
\subsection{Calltarget Analysis}
\label{section:calltargetanalysis}
For our policy we need to classify our calltargets according to the parameters they provide. Underestimations are allowed, however overestimations shall not be permitted. For this purpose we employ a customizable modified liveness analysis algorithm, which we will show first. We then present our versions for a \emph{count} and a\emph{type} based policy. Furthermore, we need to be aware of certain corner cases, which we will discuss at the end.

\textbf{Liveness Analysis}
A variable is alive before the execution of an instruction, if at least one of the originating paths performs a read access before any write access  on that variable. If applied to a function, this calculates essentially the variables that need to be alive at the beginning, which in essense are its parameters.
We based Algorithm~\ref{alg:liveness} on the liveness analysis algorithm in Khedker \textit{et al.}~ \cite{khedker2009data}, which essentially is a depth first traversal of blocks. For customization we rely on the implementation of several functions($\mathcal{S}^\mathcal{L}$ is the set of possible register states depending on the specific liveness implementation):

$\texttt{merge\_v} : \mathcal{S}^\mathcal{L} \times \mathcal{S}^\mathcal{L} \mapsto \mathcal{S}^\mathcal{L}$, which describes how to merge a set of states resulting from several paths.

$\texttt{merge\_h} : \mathcal{P}(\mathcal{S}^\mathcal{L}) \mapsto \mathcal{S}^\mathcal{L}$, which describes how to merge the current state with the following state change.

$\texttt{analyze\_instr} : \texttt{INSTR} \mapsto \mathcal{S}^\mathcal{L}$, which calculates the state change that occurs due to the given instruction 

$\texttt{succ} : \texttt{INSTR}^* \mapsto \mathcal{P}(\texttt{INSTR}^*)$, which calculates the successors of the given block.

\begin{algorithm}[h!]
 	\SetAlgoLined
	\SetKwInOut{Input}{Input}
      \SetKwInOut{Output}{Output}
  \Input{block : $\texttt{INSTR}^*$}
        \Output{$\mathcal{S}^\mathcal{L}$}
        \BlankLine
	\SetKwProg{Fn}{Function }{ is}{end}
	\Fn{\texttt{analyze} (block : $\texttt{INSTR}^*$) : $\mathcal{S}^\mathcal{L}$}
	{
 	state = Bl                                                  \Comment*[r]{Initialize the state}
 	
 	\ForEach{inst $\in$ block}{
 	
 		state' = \texttt{analyze\_instr}(inst)	\Comment*[r]{Calculate changes}

		state = \texttt{merge\_h}(state, state')                     \Comment*[r]{Merge changes}
	}

	states = \{\}                                               \Comment*[r]{Set of surccessor states}
	
	blocks = \texttt{succ(block)}                                        \Comment*[r]{Get successors}
	
	\ForEach{block' $\in$ blocks} {
	
 		state' = \texttt{ analyze}(block') \Comment*[r]{Analyze successor }
 		
		states = states $\cup$ \{ state' \} \Comment*[r]{Add successor states}
	}

	state' = \texttt{merge\_h }(states)	\Comment*[r]{Merge successor states}

	\Return merge\_v(state, state')                             \Comment*[r]{Merge to final state}

	}
\caption{Basic block liveness analysis.}
\label{alg:liveness}
\end{algorithm}

In our specific case, the function \texttt{analyze\_instr} needs to also handle non jump and non fallthrough successors, as these are not handled by DynInst. Essentially there are four relevant cases: 1) If the current instruction is an indirect call or a direct call and the chosen implementation should not follow calls, then return a state where all registers are considered to be written before read. 2) If the current instruction is a direct call and the chosen implementation should follow calls, then we start an analysis of the target function an return its result. 3) If the instruction is a constant write (e.g., xor of two registers), 
then we remove the read portion before we return the decoded state. 4) In any other case, we simply return the decoded state.
This leaves us with the two undefined merge functions and the undefined liveness state $\mathcal{S}^\mathcal{L}$. In the following two paragraphs we will present two implementation variants: first similar to TypeArmour a \emph{count} based policy and second our \emph{type} based policy.

\textbf{Required Parameter Count} To implement the \emph{count} policy, we only need a coarse representation of the state of one register, thus we use the same representation as TypeArmor: 1) $W$ represents write before read access, 2) $R$ represents read before write access, and 3) $C$ represents the absence of access.
This gives us the $S^\mathcal{L} = \{ C, R, W \}$ as register state, which translates to the register super state $\mathcal{S}^\mathcal{L} = (S^\mathcal{L})^{16}$.
We implement \texttt{merge\_v} in such a way that a state within a superstate is only updated if the corresponding register has yet to be accesses, as represented by $C$. Our reasoning is that the first access is the relevant one to determine read before write.

TODO  \texttt{merge\_h} (depends on numbers)

The index of highest parameter register based on the used call convention that has the state R is considered to be the number of parameters a function at least requires to be prepared by a callsite.

%
%This leaves us with the two merge functions remaining undefined and we will leave the implementation of these and the interpretation of the  liveness state $\mathcal{S}^\mathcal{L}$ into parameters up to the following subsections.
%
%\textbf{Required Parameter Count.}
%\label{subsection:requiredparamcount}
%To implement the \emph{count} policy, we only need a coarse representation of the state of one register, thus we use the same representation as TypeArmor:
%\textit{1)} $W$ represents write before read access,
%\textit{2)} $R$ represents read before write access, and
%\textit{3)} $C$ represents the absence of access.
%
%This gives us the following register state $S^\mathcal{L} = \{ C, R, W \}$ which translates to the register super state $\mathcal{S}^\mathcal{L} = (S^\mathcal{L})^{16}$.
%We are only interested in the first occurrence of a $R$ or $W$ within one path, as following reads or writes do not give us more information. 
%Therefore, our vertical merge function ($merge\_v$) behaves in the following way that only when the first given state is $C$, 
%is the return value the second state and in all other cases it will return the first state.
%
%\begin{align}
%merge\_v^{r} (cur, delta) &= \left\{
%  \begin{array}{lr}
%     delta & cur = C \\
%     cur & otherwise
%  \end{array}
%\right. \\Liveness analysis of a 
%merge\_v (cur, delta) &= (s'_0, ... s'_15) \text { with } s'_j = merge\_v^{r}(cur_j, delta_j)
%\end{align}

%Our horizontal merge($merge\_h$) function is a simple pairwise combination of the given set of states, 
%which are then combined with a union like operator with $W$ preceding $R$ preceding $C$.
%\begin{align}
%merge\_h(\{s\}) &= s\\
%merge\_h(\{s\} \cup s') &= s \circ merge\_h(s')
%\end{align}

%
%We have three viable possibilities for our combination operator $\circ$, depicted in Table \ref{fig:COUNTlivenessmapping}, which all give priority to $W$:
%\begin{itemize}
%\item [$\bigsqcap^{\mathcal{L}}$] is what we call the destructive combination operator, as it returns W on any mismatch.
%\item [$\bigcap^{\mathcal{L}}$] is what we call the intersection operator, as it returns C, when combining C and R, similar to an intersection.
%\item [$\bigcup^{\mathcal{L}}$] is what we call the union operator, as it returns R, when combining C and R similar to a union.
%\end{itemize}


\newcolumntype{?}{!{\vrule width 1pt}}
%
%\begin{table}
%
%% \centering
%\resizebox{\columnwidth}{!}{%Liveness analysis of a 
%\begin{tabular}{c?c|c|c}
%$\bigsqcap^{\mathcal{L}}$ & C & R & W\\
%\Xhline{1pt}
%C & C & W & W\\
%\hline
%R & W & R & W\\
%\hline
%W & W & W & W
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigcap^{\mathcal{L}}$  & C & R & W\\
%\Xhline{1pt}
%C & C & C & W\\
%\hline
%R & C & R{todo} & W\\
%\hline
%W & W & W & W
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigcup^{\mathcal{L}}$  & C & R & W\\
%\Xhline{1pt}
%C & C & R & W\\
%\hline
%R & R & R & W\\
%\hline
%W & W & W & W
%\end{tabular}}
%\caption{Different mappings for combining two liveness state values in horizontal matching for the \emph{count} policy.}
%
%\label{fig:COUNTlivenessmapping}
%\end{table}

%The index of highest parameter register based on the used call convention that has the state R is considered to be the number of parameters a function at least requires to be prepared by a callsite.

\textbf{Required Parameter Wideness.}
\label{subsection:requiredparamwideness}
To implement the \emph{type} policy, we need a finer representation of the state of one register:
\textit{1)} $W$ represents write before read access,
\textit{2)} $r8, r16, r32, r64$ represents read before write access with 8-, 16-, 32-, 64-bit wideness, and
\textit{3)} $C$ represents the absence of access.
%\begin{enumerate}
%\item Was the register written to before its value could be read ? \\ We represent this with the state $W$.
%\item How much was read from the register before its value was overwritten? \\ We represent this with the states $\{ r8, r16, r32, r64 \}$ 
%using $R$ as a placeholder for arbitrary reads.
%\item Did neither read nor write access occur for the register ? \\ We represent this with the state $C$.
%\end{enumerate}
This gives us the following $S^\mathcal{L} = \{ C, r8, r16, r32, r64, W \}$ register state which translates to the register super state 
$\mathcal{S}^\mathcal{L} = (S^\mathcal{L})^{16}$.
%Now, we assume that unless the instructions we are looking at does discard the value it is reading (\texttt{xor rax rax} would be such 
%an instruction that we call const\_write) that reading does precede the writing withing one instruction.
As there could be more than one read of a register before it is written, we might be interested in more than just the first occurrence of a write or read on a path. 
To allow this we allow our merge operations to also return the value $RW$, which represents the existence of both read and write access and then can use $W$ as an end 
marker of sorts.
% We arrive therefore at three possible vertical merge functions:
%\begin{itemize}
%	\item The same vertical merge operator as used in the \emph{count} policy, which only gives us the first non $C$ state ($merge\_v^{r}$).
%	\item A vertical merge operator that conceptually intersects all read accesses along a path until the first write occurs ($merge\_v^{i}$).
%	\item A vertical merge operator that conceptually calculates the union of all read accesses along a path until the first write occurs ($merge\_v^{u}$).
%\end{itemize}
Therefore, our vertical merge operator conceptually intersects all read accesses along a path until the first write 
occurs ($merge\_v^{i}$). In any other case it behaves like the previously mentioned vertical merge function.
%Our horizontal merge function is a simple pairwise combination of the given set of states:
%\begin{align}
%merge\_h(\{s\}) &= s\\
%merge\_h(\{s\} \cup s') &= s \circ merge\_h(s')
%\end{align}
Our horizontal merge($merge\_h$) function is again a simple pairwise combination of the given set of states, which are then combined with a union 
like operator with $W$ preceding $WR$ preceding $R$ preceding $C$. Unless one side is $W$, read accesses are combined in such a way that always the higher one is chosen.

%The results of our experiments with the implementation of calltarget classification gave presented us with essentially one possible candidate
%that we can base our horizontal merge function on, namely the union operator with an analysis function that follows into direct calls. The 
%basic schema of the merging is depicted in \ref{tbl:TYPECTunion} and it essentially behaves as if it was the union operator (when both states
%are set, the higher one is chosen). However, we have to account for W being used as an end marker, which is why we added mapping for RW, 
%which is essentially that. 
%
%\begin{table}[h]
%\centering
%% \resizebox{\columnwidth}{!}{%
%\begin{tabular}{c?c|c|c|c}
%$\bigcup^{\mathcal{L}}$  & C & R & W & RW\\
%\Xhline{1pt}
%C & C & R & W & RW\\
%\hline
%R & R & $\text{R}^{\cup}$ & W & $\text{R}^{\cup}$W\\
%\hline
%W & W & W & W & W\\Liveness analysis of a 
%\hline
%RW & RW & $\text{R}^{\cup}$W & W & RW\\
%\end{tabular}
%% }
%\caption{The union mapping operator for liveness in the \emph{type} policy.}
%\label{tbl:TYPECTunion}
%\end{table}

\textbf{Variadic Functions.}
\label{subsection:variadicfunctions}

\begin{figure}[thp] % the figure provides the caption
\centering          % which should be centered
\begin{tabular}{c}  % the tabular makes the listing as small as possible and centers it
\footnotesize
\begin{lstlisting}
00000000004222f0 <make_cmd>:
 4222f0:push   %r15
 4222f2:push   %r14
 4222f4:push   %rbx
 4222f5:sub    $0xd0,%rsp
 4222fc:mov    %esi,%r15d
 4222ff:mov    %rdi,%\begin{figure}[!h]
 422302:test   %al,%al
 422304:je     42233d <make_cmd+0x4d>
 422306:movaps %xmm0,0x50(%rsp)
 42230b:movaps %xmm1,0x60(%rsp)
 422310:movaps %xmm2,0x70(%rsp)
 422315:movaps %xmm3,0x80(%rsp)
 42231d:movaps %xmm4,0x90(%rsp)
 422325:movaps %xmm5,0xa0(%rsp)
 42232d:movaps %xmm6,0xb0(%rsp)
 422335:movaps %xmm7,0xc0(%rsp)
 42233d:mov    %r9,0x48(%rsp)
 422342:mov    %r8,0x40(%rsp)
 422347:mov    %rcx,0x38(%rsp)
 42234c:mov    %rdx,0x30(%rsp)
 422351:mov    $0x50,%esi
 422356:mov    %r14,%rdi
 422359:callq  409430 <pcalloc>
\end{lstlisting}
\end{tabular}
\caption{ASM code of the \texttt{make\_cmd} function with optimize level O2, which has a variadic parameter list.}
\label{fig:asmvariadic}
\end{figure}

Variadic functions are special functions in C/C++ that have a basic set of parameters, 
which they always require and a variadic set of parameters, which as the name suggests 
may vary. A prominent example of this would be the $printf$ function, which is used 
to output text to $stdout$.
This type of functions allow for an easier processing of parameters where
usually all potential variadic parameters are moved into a contiguous block of memory, 
as can be observed in the assembly depicted Figure \ref{fig:asmvariadic}.
Our analysis interprets that as a read access on all parameters and thus,
we arrive at a problematic overestimation. 

Our solution to this problem is to find these spurious reads and ignore them. A compiler will implement this type of operation very 
similar for all cases, thus we can achieve this using the following steps:
\textit{1)} we look for what we call the xmm-passthrough block, which entirely consist of moving the values of registers \texttt{xmm0} to 
\texttt{xmm7} into contiguous memory, % (in our case basic block [\texttt{0x422306}, \texttt{0x42233d} [ ).
\textit{2)} we look at the predecessor of the xmm-passthrough block, which we call the entry block (in our case basic block %[\texttt{0x4222f0},\texttt{0x4222f2} [ )
Check if the successors of the entry block consist of the xmm-passthrough block and the successor of the 
xmm-passthrough block, which we call the param-passthrough block, and
%(in our case basic block [\texttt{0x42233d}Liveness analysis of a , \texttt{0x42235e} [ )
\textit{3)} We look at the param-passthrough block and set all instructions that move the value of a parameter register into memory to be
ignored. %(in our case the instructions \texttt{0x42233d}, \texttt{0x422342}, \texttt{0x422347} and \texttt{0x42234c})

\textbf{Ignoring Reads.} When one instruction writes and reads a register at the same time we give the read access precedence, however there are exceptions (also mentioned in TypeArmor, however we expand slightly on that):
\textit{1)} \texttt{xor \%rax, \%rax} is the first obvious scenario, as it will always result in \texttt{\%rax} holding the value 0,
\textit{2)} \texttt{sub \%rax, \%rax} is probably the next scenario, as it results also in \texttt{\%rax} also holding the value 0, and
\textit{3)} \texttt{sbb \%rax, \%rax} is also relevant, however it will not result in a constant value and based on the current state might either result in \texttt{\%rax} holding the value 0 or 1.

\begin{algorithm}[!ht]
	\SetAlgoLined
	\SetKwInOut{Input}{Input}
        \SetKwInOut{Output}{Output}
        \Input{basic block}
        \Output{$\mathcal{S}^\mathcal{R}$}
        \BlankLine
	\SetKwProg{Fn}{Function}{ is}{end}
	\Fn{analyze(block : BasicBlock) : $\mathcal{S}^\mathcal{R}$}
	{
 	state = Bl                                   \Comment*[r]{Some comment}
 	
 	\ForEach{inst $\in$ reversed(block)}{
 	
 		state' = analyze\_instr(inst)        \Comment*[r]{Some comment}
 		
		state = merge\_v(state, state')      \Comment*[r]{Some comment}
	}

	states = \{\}                                \Comment*[r]{Some comment}
	
	blocks = pred(block)                         \Comment*[r]{Some comment}
	
	\ForEach{block' $\in$ blocks} {
	
 		state' = analyze(block')             \Comment*[r]{Some comment}
 		
		states = states $\cup$ \{ state' \}  \Comment*[r]{Some comment}
	}

	state' = merge\_h (states)                   \Comment*[r]{Some comment}

	\Return merge\_v(state, state')              \Comment*[r]{Some comment}

	}
\caption{Basic block reaching definition analysis.}
\label{alg:reaching}
\end{algorithm}

\subsection{Callsite Analysis}
\label{section:callsiteanalysis}
For either \emph{count} or \emph{type} policy to work, we need to arrive at an overestimation of the provided parameters by any indirect 
callsite existing within the targeted binary. We will employ a modified version of reaching analysis that tracks registers instead of 
variables to generate the needed overestimation. As our algorithm will be customizable, we look at the required merge functions to 
implement \emph{count} and \emph{type} policy. 

\textbf{Reaching Definitions.}
\label{subsection:reachindefinitionstheory}
An assignment of a value to a variable is a reaching definition at the end of a block $n$, if that definition is present within at 
least one path from start to the end of the block $n$ without being overwritten by another value assignment to the same variable. 
We employ reaching definitions analysis, because we are looking for the parameters a callsite provides. This essentially 
requires the last known set of definitions that reach the actual call instruction within the parameter registers.

%The book~\cite{khedker2009data} defines reaching definition analysis on blocks in the following manner:
%\begin{subequations}
%\label{eq:reachingbasedef}
%\begin{align}
%In_n &:= \left\{
%  \begin{array}{lr}
%    Bl & \text{n is start block}\\
%    \underset{p \in pred(n)}{\bigcup} Out_p & \text{otherwise}
%  \end{array}
%\right. \label{eq:reachingbasedefInt}\\
%Out_n &:= (In_n - Kill_n) \cup Gen_n \label{eq:reachingbasedefOut}
%\end{align}
%\end{subequations}
%$Bl$ is the default state at the start of a path of execution and in our case reaching that state would mean that we do not 
%know whether a value has been provided for the variable and therefore we assume that one has been provided, reaching an 
%overestimation. The set $Kill_n$ describes all definitions that are removed within this block, meaning that the value of 
%a variable has been overwritten. The set $Gen_n$ describes the new definitions that have been provided by the block $n$, 
%meaning that the value of a variable has been assigned. Considering this, we can assume that $Gen_n \subseteq Kill_n$, 
%as we can always create new definitions, but not simply remove definitions without assigning a new value to the variable.


%
%
%However, we cannot use reaching definition analysis as is, because the analysis is again based on potentially unbound 
%variable sets, while we are restricted to a finite number of registers and states. This time however the analysis provides us with an overestimation, 
%we however want to get a result as close as possible so we again want to customize merge functions. Furthermore, we have to define how 
%to interpret the changes occuring withing one block based on the the change caused by its instructions. Considering this, w, we 
%arrive at algorithm \ref{alg:reaching} to compute the liveness state at the start of a basic block.
The book~\cite{khedker2009data} defines reaching definition analysis on blocks, which we use to arrive at algorithm depicted in Algorithm~\ref{alg:reaching} to compute 
the liveness state at the start of a basic block. We apply the reaching analysis at each indirect callsite directly before each call instruction.

This algorithm relies on various functions that can be used to configure its behavior. We need to define the 
function $merge\_v$, which describes how to compound the state change of the current instruction and the current state, 
the function $merge\_h$, which describes how to merge the states of several paths, the instruction analysis function
$analyze\_instr$. The function $pred$, which retrieves all possible predecessors of a block won't be implemented by us, 
because we rely on the DynInst instrumentation framework to achieve the following.
\vspace{-.3cm}
\begin{subequations}
\label{eq:livenesscustom}
\begin{align}
merge\_v &: \mathcal{S}^\mathcal{R} \times \mathcal{S}^\mathcal{R} \mapsto \mathcal{S}^\mathcal{L}\\
merge\_h &: \mathcal{P}(\mathcal{S}^\mathcal{R}) \mapsto \mathcal{S}^\mathcal{R}\\
analyze\_instr &: \mathcal {I} \mapsto \mathcal{S}^\mathcal{R} \\
pred &: \mathcal{I} \mapsto \mathcal{P}(\mathcal{I})
\end{align}
\end{subequations}
\vspace{-.8cm}

As the $analyze\_instr$ function calculates the effect of an instruction and is the heart of the analyze function. It will also 
handle non jump and non fall-through successors, as these are not handled by DynInst in our case. We essentially have three cases that we handle:
\textit{1)} if the instruction is an indirect call or a direct call but we chose not to follow calls, then return a state where all trashed 
are considered written,
\textit{2)}  if the instruction is a direct call and we chose to follow calls, then we spawn a new analysis and return its result, and
%\item if the instruction is a constant write (\textit{e.g.,} xor of two registers) then we remove the read portion before we return the decoded state
\textit{3)} in all other cases we simply return the decoded state.

This leaves us with the two merge functions remaining undefined and we will leave the implementation of these and the interpretation of 
the liveness state $\mathcal{S}^\mathcal{L}$ into parameters up to the following subsections.

%We have yet to define the functions $merge\_v$, which describes how to compound a function and the outgoing state, the function $merge\_h$, which describes how to merge the states of several paths and the function $pred$, which essentially gives us the predecessors of the current instruction. To prevent cycles we keep track of the instructions visited within the current path and omit any instruction on the current path from the result of $pred$. These functions, the reaching state $\mathcal{S}^\mathcal{R}$  and its interpretation into parameters will be defined in the following subsections.
%
%
%\subsection{Backward Graph Traversal}
%\label{subsection:backwardgraphtraversal}

\textbf{Provided Parameter Count.}
\label{subsection:providedparamcount}
To implement the \emph{count} policy, we only need a coarse representation of the state of one register, 
thus we use the same representation as TypeArmor:
\textit{1)} $T$ represents a trashed register,
\textit{2)} $S$ represents a set register (written to), and
\textit{3)} $U$ represents an untouched register.
This gives us the following $S^\mathcal{L} = \{ T, S, U \}$  register state which translates to the register super state $\mathcal{S}^\mathcal{R} = (S^\mathcal{R})^{16}$.

We are only interested in the first occurrence of a $S$ or $T$ within one path, as following reads or writes do not give us more information. 
Therefore, our vertical merge function ($merge\_v$) behaves in the following way that only when the first given state is $U$, is the return value the 
second state and in all other cases it will return the first state.
%
%We are only interested in the first occurrence of a S or T within one path, as following reads or writes do not give us more information.
%Therefore, we can define our vertical merge function in the following way:
%\begin{align}
%merge\_v^{r} (cur, delta) &= \left\{
%  \begin{array}{lr}
%     delta & cur = U \\
%     cur & otherwise
%  \end{array}
%\right. \\
%merge\_v (cur, delta) &= (s'_0, ... s'_15) \text { with } s'_j = merge\_v^{r}(cur_j, delta_j)
%\end{align}


Our horizontal merge($merge\_h$) function is a simple pairwise combination of the given set of states, which are then combined with a union 
like operator with $T$ preceding $S$ preceding $U$.
%
%Our horizontal merge function is a simple pairwise combination of the given set of states:
%\begin{align}
%merge\_h(\{s\}) &= s\\
%merge\_h(\{s\} \cup s') &= s \circ merge\_h(s')
%\end{align}
%
%We have four viable possibilities for our combination operator $\circ$, depicted in table \ref{fig:COUNTreachingmapping}, which all (except one) give priority to $T$:
%\begin{itemize}
%\item [$\bigsqcap^{\mathcal{R}}$] is what we call the destructive combination operator, as it returns T on any mismatch.
%\item [$\bigcap^{\mathcal{R}}$] is what we call the intersection operator, as it returns U, when combining U and S, similar to an intersection.
%\item [$\bigcup^{\mathcal{R}}$] is what we call the union operator, as it returns S, when combining U and S similar to a union.
%\item [$\bigsqcup^{\mathcal{R}}$] is what we call the true union operator, as it gives S precedence over everything and returns T or 
%U only when both sides are T or U being more inclusive than a union.
%\end{itemize}

\newcolumntype{?}{!{\vrule width 1pt}}
%
%\begin{table}
%% \centering
%{
%\resizebox{\columnwidth}{!}{%
%\begin{tabular}{c?c|c|c}
%$\bigsqcap^{\mathcal{R}}$ & U & S & T\\
%\Xhline{1pt}
%U & U & T & T\\
%\hline
%S & T & S & T\\
%\hline
%T & T & T & T
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigcap^{\mathcal{R}}$  & U & S & T\\
%\Xhline{1pt}
%U & U & U & T\\
%\hline
%S & U & S & T\\
%\hline
%T & T & T & T
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigcup^{\mathcal{R}}$  & U & S & T\\
%\Xhline{1pt}
%U & U & S & T\\
%\hline
%S & S & S & T\\
%\hline
%T & T & T & T
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigsqcup^{\mathcal{R}}$  & U & S & T\\
%\Xhline{1pt}
%U & U & S & T\\
%\hline
%S & S & S & S\\
%\hline
%T & T & S & T
%\end{tabular}}
%}
%
%\caption{Different mappings for combining two reaching state values in horizontal matching for the \emph{count} policy.}
%
%\label{fig:COUNTreachingmapping}
%\end{table}

The index of the highest parameter register based on the used call convention that has the state S is considered to be the number of parameters a callsite at most prepares.

\textbf{Provided Parameter Wideness.}
\label{subsection:providedparamwideness}
To implement the \emph{type} policy, we need a finer representation of the state of one register:
\textit{1)} $T$ represents a trashed register,
\textit{2)} $s8, s16, s32, s64 S$ represents a set register with  8-, 16-, 32-, 64-bit  wideness, and
\textit{3)} $U$ represents an untouched register.
%\begin{itemize}
%\item Was the register value trashed ? \\ We represent this with the state T.
%\item Was the register written to and how much ? \\ We represent this with the states $\{ s64, s32, s16, s8 \}$ using S as a placeholder for arbitrary writes.
%\item Was the register neither trashed nor written to ? \\ We represent this with the state U.
%\end{itemize}
This gives us the following $S^\mathcal{L} = \{ T, s64, s32, s16, s8, U \}$ register state which translates to the register 
super state $\mathcal{S}^\mathcal{R} = (S^\mathcal{R})^{16}$.

Again, we are only interested in the first occurrence of a state that is not $U$ in a path, as following reads or writes do not give us more information. 
Therefore, we can use the same vertical merge function as for the \emph{count} policy, which is essentially a pass-through until the first non $U$ state.

Our horizontal merge($merge\_h$) function is a simple pairwise combination of the given set of states, which are then combined with a union like 
operator with $T$ preceding $S$ preceding $U$. When both states are set, we pick the higher one.

%
%Our horizontal merge function is again a simple pairwise combination of the given set of states:
%\begin{align}
%merge\_h(\{s\}) &= s\\
%merge\_h(\{s\} \cup s') &= s \circ merge\_h(s')
%\end{align}
%
%However, we have different possibilities regarding the merge operator. Experiments with our implementations for callsite 
%classification in the \emph{count} policy have given us the following results:
%\begin{itemize}
%\item The best candidate to minimize the problematic matches is the union operator without following direct calls.
%\item The best candidate to maximize precision is the intersection operator with following direct calls.
%\end{itemize}
%
%We therefore arrive at three viable possibilities for our combination operator $\circ$, depicted in table \ref{fig:TYPEreachingmapping}, 
%which all (except one) give priority to $T$:
%\begin{itemize}
%\item [$\bigcap^{\mathcal{R}}$] is what we call the intersection operator, as it returns U, when combining U and S, similar to an 
%intersection furthermore we also calculate the intersection of states when both states are set 
%(the lower of the two is returned).
%\item [$\bigsqcap^{\mathcal{R}}$] is what we call the half intersection operator, as it returns U, when combining U and S, 
%similar to an intersection but we calculate the union of states when both states are set (the higher of the two is returned).
%\item [$\bigcup^{\mathcal{R}}$] is what we call the union operator, as it returns S, when combining U and S similar to a union
%furthermore we calculate the union of states when both states are set (the higher of the two is returned).
%\end{itemize}
%
%\begin{table}
%
%% \centering
%\resizebox{\columnwidth}{!}{%
%\begin{tabular}{c?c|c|c}
%$\bigcap^{\mathcal{R}}$  & U & S & T\\
%\Xhline{1pt}
%U & U & U & T\\
%\hline
%S & U & $\text{S}^{\cap{}{}}$ & T\\
%\hline
%T & T & T & T
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigsqcap^{\mathcal{R}}$  & U & S & T\\
%\Xhline{1pt}
%U & U & U & T\\
%\hline
%S & U & $\text{S}^{\cup{}{}}$ & T\\
%\hline
%T & T & T & T
%\end{tabular}
%\begin{tabular}{c?c|c|c}
%$\bigcup^{\mathcal{R}}$  & U & S & T\\
%\Xhline{1pt}
%U & U & S & T\\
%\hline
%S & S & $\text{S}^{\cup{}{}}$ & T\\
%\hline
%T & T & T & T
%\end{tabular}}
%
%\caption{Different mappings for combining two reaching state values in horizontal matching for the \emph{type} policy.}
%\label{fig:TYPEreachingmapping}
%\end{table}

Our experiments with this implementation showed two problems regarding provided wideness detection.  Parameter lists with \textit{holes} and address wideness underestimation, 
furthermore register extension instructions are also cause of problems. To reduce runtime, we also restricted the maximum path depth to 10 blocks.

\paragraph{Parameter Lists with \textit{Holes}.} This refers to parameter lists that show one or more \texttt{void} parameters between start to the last actual parameter. 
These are not existent in actual code but our analysis has the possibility of generating them through the merge operations. An example would be the following: 
A parameter list of $(64, 0, 64, 0, 0, 0)$ is concluded, although the actual parameter list might be $(64, 32, 64, 0, 0, 0)$. While the trailing 0es are 
what we expect, the 0 at the second parameter position will cause trouble, because it is an underestimation at the single parameter level, which we need to avoid.
Our solution is to simply scan our reaching analysis result for these holes and replace them with the wideness $64$, causing a (possible) overestimation.

\paragraph{Address Wideness Unterestimation.} This refers to the issue that while in the callsite a constant value of 32-bit is written to a register, however 
the calltarget uses the whole 64-bit register. This can occur when pointers are passed from the callsite to the calltarget. Specifically this happens 
when pointers to memory inside the \texttt{.bss}, \texttt{.data} or \texttt{.rodata} section of the binary are passed.
Our solution is to enhance our instruction analysis to watch out for constant writes. In case a 32-bit constant value write is detected, we check if the
value is an address within the \texttt{.bss}, \texttt{.data} or \texttt{.rodata} section of the binary. If this is the case, we simply return a write access of 64-bit 
instead of 32-bit. This is not problematic, because we are looking for an overestimation of parameter wideness.
It should be noted that the same problem can arise when a constant write causes the value 0 to be written to a 32-bit register. We use the same solution
and set the wideness to 64-bit instead of 32-bit.
%
%\subsection{Address Taken Analysis}
%\label{section:addresstakenanalysis}
%As of now, we use the maximum available set of calltargets---the set of all function entry basic blocks---as input for our algorithm. 
%To restrict the number of calltargets per callsite even further, we explored the possibility of incorporating an address taken analysis
%into our application. We base our theory on the paper by Zhang \textit{et al.}~\cite{mingwei:sekar}, which introduced various types of taken
%addresses. An address is considered to be taken, when it is loaded into memory or a register.
%
%\textbf{Address Taken Targets.}
%Based on the notions of \cite{mingwei:sekar}, which classified taken addresses into several types of indirect control flow targets,
%we only chose { Code Pointer Constants (CK)} and discarded the others:
%\begin{itemize}
%
%\item { Code Pointer Constants (CK)} are addresses that are calculated during the compilation of the binary and point within
%the possible range of addresses in the current module or to instruction boundaries. We are however only interested in addresses
%that directly point to an entry basic block of a function, as these are the only valid targets for any callsite.
%
%\item { Computed code pointers (CC)} are the result of simple pointer arithmetic, however these are only used for intra-procedural jumps. 
%We rely on DynInst to resolve those and only focus on indirect callsites, therefore these are of no interest to us.
%
%\item{ Exception handling addresses (EH)} are used to handle exceptions within C++ functions and are modeled as jumps within the function. 
%These are therefore within the normal control flow that we rely on DynInst to resolve for us.
%
%\item{ Exported function addresses (ES)} are essentially functions that point outside of our current module (usually to dynamically 
%linked libraries) and are implemented as jumps, which are of no concern to us, because our analysis is only concerned about the current object.
%
%\item { Return addresses (RA)}, which are the addresses next to a call instruction, are also of no interest to us, because we only 
%implement forward { control flow integrity}.
%\end{itemize}
%
%\textbf{Binary Analysis.}
%Our approach of identifying taken addresses consists of two steps: First, we iterate over the raw binary content of data sections. Second,
%we iterate over all functions within the disassembled binary. We rely on DynInst to provide us with the boundaries of the sections inside
%the binary and in case of shared libraries with the needed translation to current memory addresses:
%
%\begin{itemize}
%\item We look at three different data sections of the binary, which could possibly contain taken addresses: the .data, .rodata and .dynsym
%sections. As \cite{mingwei:sekar} proposed, we slide a four byte window over the data within those sections and look for addresses that
%point to function entry blocks. However, we are looking at x64 binaries therefore we additionally use an eight byte window. In case of 
%shared libraries, we need to let DynInst translate the raw address, we extracted, so we can perform the function check.
%
%\item We specifically look for instructions that load a constant value into a register or memory, and again check whether the address 
%points to the entry block of a function.
%\end{itemize}

%\section{Runtime Enforcement}
%\label{section:runtimeenforcement}
%
%\subsection{Calltarget Annotation}
%\label{subsection:patchingschema}
%
%\subsection{Callsite Instrumentation}
%\label{subsection:patchingschema}


