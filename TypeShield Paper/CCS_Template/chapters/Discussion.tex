\section{Discussion}
\label{chapter:Discussion}

\subsection{Comparison with TypeArmor}
\label{section:comptype}
We are looking at two sets of results. First of all, we compare the overall precision of our implementation
of the COUNT policy with the results from TypeArmor to set the perspective for the precision of our TYPE 
policy. We cannot compare data regarding overestimations of calltargets or underestimations of callsites, 
as TypeArmor did not provide sufficient data. The second point of comparison is the reduction of calltargets
per callsite, however, this comparison is rather crude, as we most surely do not have the same measuring
environment and not sufficient data to infer its quality.

\subsubsection{Precision of Classification}
TypeArmor reports a geometric mean of 83.26\% for the perfect classification of calltargets regarding 
parameter count in optimization level O2, which compares rather well to our result of 82.24\%. Regarding
the perfect classification of callsites we report a geometric mean of 81.6\% perfect classification 
regarding parameter count, while TypeArmor reports a geometric mean of 79.19\%. However, we also have
a geometric mean of about 7\% regarding underestimations in the callsite classification with an upper
bound of 16\%, while TypeArmor reports that it does not incur underestimations in their callsites.
Now, for our type based classification we incur the cost for two error sources. First, the error from
the parameter count classification, which we base our type analysis on and second for the type analysis
itself. The numbers for the perfect classification of calltargets regarding parameter types we report a
72.25\% geometric mean of perfect classification, which is 87.85\% of our precision regarding parameter
counts. However, we report a geometric mean of 57.36\%
for perfect classification of callsites, which although seemingly low, is still 69.74\% of our precision
regarding parameter counts.

\subsubsection{Reduction of Available Calltargets}
While our count based precision focused implementation achieves a reduction in the same ballpark as
TypeArmor regarding our test targets, lets us believe that our implementation of their classification
schema is a sufficient approximation to compare against. However, we cannot safely compare those numbers,
as the information regarding their test environment are rather sparse and the only data available is the
median, which in our opinion does discard valuable information from the actual result set. This is the
main reason we implemented an approximation, because we needed more metrics to compare \textsc{TypeShield}
and TypeArmor regarding calltargets. Using average and sigma, we can report that our precision focused
type based classification can reduce the number of calltargets, by up to 20\% more than parameter number
based classification with an overall reduction of about 9\%.

\subsection{TypeArmor Discrepancies}
\label{section:discrep}
As we have no access to source code of TypeArmor, we implemented an approximation
of TypeArmor. Using this approximation we found some discrepancies between the data that we collected
and data that was presented in the TypeArmor paper.
A minor discrepancy between our results and the results of TypeArmor is that, while they basically implemented
what we call a destructive merge operator for the liveness analysis. However, our data suggests that this
operator is marginally inferior to the union path merge operator, when we compared them in our implementation.
A major concern is the classification of calltargets, while we were able to reduce the number of overestimations
of calltargets regarding parameter counts to essentially 0, the number of underestimations of calltarget did
stay at a geometric mean of 7\%. This error rate is rather large when compared to the reported 0\% underestimation
of TypeArmor, however we are not entirely sure what has caused this discrepancy. A possibility is the differing
test environments, or a bug within our implementation that we are not aware of, or simply reaching definitions
analysis alone is not the best possible algorithm for this particular problem.

\subsection{Improving \textsc{TypeShield}}
\label{section:venuesimp}
To improve our type analysis, we see at least two possibilities. Incorporating refined data flow analysis and 
expanding the scope to also include memory. The main point of improvement is not the precision but for now 
more importantly the reduction of underestimations in the callsite analysis.

To refine the data flow analysis, we propose the actual tracking of data values and simple operations, as these
can be used to better differentiate the actual wideness stored within the current register. The highest gain, 
we see here would be the establishment of upper and lower bounds regarding values within the register, which 
would allow for more sophisticated callsite and calltarget invariants. Essentially we would have to resort 
to symbolic execution or some other sort of precise abstract interpretation.

Expanding the scope to also include memory, is another possible way of improving the type analysis, as it 
would allow us to distinguish normal 32-bit or 64-bit values and pointer addresses. Although we already have a 
limited approach of that in our reaching implementation, we still see room for improvement, as we only check
whether a value is within one of three binary sections or 0.

\subsection{Limitations of \textsc{TypeShield}}
\label{section:limit}
First, \textsc{TypeShield} is limited by the capabilities of the DynInst instrumentation environment, where non-returning functions like exit are 
not detected reliably in some cases. As a result, we cannot test the Pure-FTP server, as it heavily relies on these functions. 
The problem is that those non-returning functions usually appear as a second branch within a function that occurs after the normal 
control flow, causing basic blocks from the following function to be attributed to the current function. This results in a malformed 
control flow graph and erroneous attribution of callsites and problematic misclassifications for both calltargets and callsites.

Second, \textsc{TypeShield} draws on variety within the binary. In particular, we rely on the fact that functions use more than only 
64-bit values or pointers within their parameter list, otherwise, \textsc{TypeShield} is equivalent to a parameter count-based implementation. 
Occurrences of such situations are quite rare, as we learned with our experiments. With a study based on source level information, we could not 
detect a difference between our \textit{type} policy and a \textit{count} policy. However, when using our tool, we were able to detect differences,
which reinforce the fact, that we do not rely on declaration of parameters, but usage of those.

Third, \textsc{TypeShield} can protect forward and backward indirect edges 
in a binary program and can complement a shadow stack~\cite{dang:asiaccs} protection technique. For this reason, we assume that \textsc{TypeShield} can run side by side with an 
ideal backward-edge protection mechanism such as a shadow stack~\cite{conti:ccs}. However, the main goal of \textsc{TypeShield} is to complement 
shadow stack based defenses which fail to account for attacks not violating the backward-edge calling conventions such as the COOP attack.

Fourth, \textsc{TypeShield} is not intended to be more precise than source code based tools such as IFCC/VTV~\cite{vtv:tice}. However, 
\textsc{TypeShield} is highly useful in situations where the source code is typically not available (\textit{e.g.,} off-the-shelf programs), 
where programs rely on many libraries, and where the recompilation of all the shared libraries is not possible. 
Further, binary based tools such as \textsc{TypeShield} can offer precise protection when source code is not available or 
recompilation is not feasible or desirable.

Finally, while a major step forward, \textsc{TypeShield} cannot thwart all possible attacks, as even solutions with access to source 
code are unable to protect against all possible attacks~\cite{carlini:bending}. In contrast, \textsc{TypeShield}, our binary-based tool, 
can stop all currently COOP attacks published to date and significantly raises the bar for an adversary when compared to
TypeArmor and similar tools. Moreover, \textsc{TypeShield} provides a strong mitigation for other types of code-reuse attacks as well.
