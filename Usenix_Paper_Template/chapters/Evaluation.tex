\section{Evaluation}
\label{chapter:Evaluation}
We evaluated our \textsc{TypeShield} by instrumenting various open source applications and analyzing the result. 
We used the two ftp server applications vsftpd (version 1.1.0) and proftpd (version 1.3.3), the two http server 
applications postgresql (version 9.0.10) and  mysql (5.1.65), the memory cache application memcached (version 1.4.20) 
and the node.js server application node (version 0.12.5). We chose these applications, which are a subset of the 
applications also used by the TypeAmor~\cite{veen:typearmor} to allow for later comparison.
In our evaluation of the two modes of 
\textsc{TypeShield}, we are trying to answer the following questions:
\begin{itemize}

 \item \textbf{RQ1:} How precise is \textsc{TypeShield} in recovering parameter count and type information for call-sites and call-targets from a given binary?

 \item \textbf{RQ2:} How effective is \textsc{TypeShield} in restricting the possible number of call-targets per call-site?

 \item \textbf{RQ3:} What is the performance overhead introduced by \textsc{TypeShield}?
 \todo[inline]{add a binary patch that does not crash none of the programs from SPEC2006.}
\todo[inline]{need a table with all the results for each of the SPEC2006 programs and a bar diagram}
 
 \item \textbf{RQ4:} What is the instrumentation overhead introduced by \textsc{TypeShield}?
 Here we measure how much the binaries increased in size after the instrumentation was added to the binaries.
\todo[inline]{Measure the size (in bytes) of the SPEC2006 testes in RQ3 before and after adding all the patches}
 
 \item \textbf{RQ5:} What level of security does \textsc{TypeShield} offer?
 We look at our implementation conceptually and assess qualitatievly whether our implementation can interfere with various classes of attacks. 
\todo[inline]{see the TypeAmor paper w.r.t. security analysis in the evaluation, a CDF figure is here required.}
 
 \item \textbf{RQ6:} Need to be defined see down?
 \todo[inline]{RQ6: need to define first this question.}
 
\end{itemize}

\textbf{Comparison Method.} As we do not have access to the source code of TypeAmor, we implemented two modes in \textsc{TypeShield}. 
The first mode of our tool is an approximate implementation of what we understand is the \textit{count} 
policy implemented by TypeAmor. The second mode is our implementation of the \textit{type} policy on
top of our implementation of the \textit{count} policy. 

\textbf{Experimental Setup.} We setup our environment within a VirtualBox (version 5.0.26r) instance, which runs Kubuntu 16.04 LTS (Linux Kernel
version 4.4.0) and has access to 3GB of RAM and 4 of 8 provided hardware threads (Intel i7-4170HQ @ 2.50 GHz).

\subsection{RQ1: Precision of \textsc{TypeShield}}
\label{section:typeshieldprecision}
\todo[inline]{In this section we need just one or two Table similar to what TypeArmor contains, first we need to define the fields which make most sense.}

To measure the precision of \textsc{TypeShield}, we need to compare the classification of call-sites and call-targets as is given by our tool to
some sort of ground truth for our test targets. We generate this ground truth by compiling our test targets using a custom compiled Clang/LLVM
compiler (version 4.0.0 trunk 283889) with a MachineFunction pass inside the x86 code generation implementation of LLVM. We essentially 
collect three data points for each call-site/call-target from our LLVM-pass:
\begin{itemize}
\item The point of origination, which is either the name of the call-target or the name of the function the call-site resides in.
\item The return type that is either expected by the call-site or provided by the call-target.
\item The parameter list that is provided by the call-site or expected by the call-target, which discards the variadic argument list.
\end{itemize}
However, before we can proceed to measure the quality and precision of \textsc{TypeShield}'s classification of call-targets and call-sites
using our ground truth, we need to evaluate the quality and applicability of the ground truth, we collected.

\subsubsection{Quality and Applicability of Ground Truth}
\label{subsection:typeshieldprecision}
To assess the applicability of our collected ground truth, we essentially need to assess the structural compatibility of our two datasets.
First, we take a look at the comparability of call-targets, which is quite high throughout optimization levels. 
Second, we take a look at the compatibility of call-sites, which is qualitatively low in the higher optimization levels, while 
five of our test targets start with 0\% mismatch in O0, mysql stays throughout all levels at a constant mismatch 
rate of around 18\%, and the others between 2\% and 17\%.

\textbf{Call-targets.} The obvious choice for structural comparison regarding call-targets is their name, as these are simply functions. 
First, we have to however remove internal functions from our data-sets like the \texttt{\_init} or \texttt{\_fini} functions, which are of no consequence for us. 
Furthermore, while C functions can simply be matched by their name as they are unique through the binary, the same cannot be said about the 
language C++. One of the key differences between C and C++ is function overloading, which allows to define several functions with the same name, as 
long as they differ in namespace or parameter type. As LLVM does not know about either concept, the Clang compiler needs to generate unique names. 
The method used for unique name generation is called mangling and composes the actual name of the function, its the return type, its name-space and the 
types of its parameter list. We therefore need to reverse this process, which is called demangling and then compare the fully typed names.
The table \ref{tbl:matchingquality} shows three data points regarding call-targets for optimization levels O0, O1, O2 and O3:
\begin{itemize}
\item The number of comparable call-targets that are found in both datasets
\item The number of call-targets that are found by \textsc{TypeShield} but not by our Clang/LLVM pass, named Clang miss
\item The number of call-targets that are found by our Clang/LLVM pass but not by \textsc{TypeShield}, named tool miss
\end{itemize}
The problematic column is the Clang miss column, as these might indicate problems with \textsc{TypeShield}. These numbers are relatively low (below 1\%) 
throughout optimization levels, with only node showing a significant higher value than the rest of around 1.6\%. The column labeled tool miss lists 
higher numbers, however these are of no real concern to us, as our ground truth pass possibly collects more data: All source files used during the 
compilation of our test-targets are incorporated into our ground truth. The compilation might generate more than one binary and therefore not 
necessary all source files are used for our test-target.

Considering this, we can safely state that our structural matching between ground truth and \textsc{TypeShield} regarding call-targets is nearly
perfect (above 98\%)

\begin{table}[h!]
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c|c|c|c}%
	\toprule
	\multicolumn{1}{c}{\bfseries O2} & \multicolumn{3}{c|}{ {\bfseries call-targets}} & \multicolumn{3}{c}{{\bfseries call-sites} }\\
	\bfseries Target & match & Clang miss &  tool miss &  match & Clang miss & tool miss% specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{csvs/matching.O2.csv}{
		%1=\target, 2=\opt, 3=\fns, 4=\fnsnotClang, 5=\fnsnotpadyn, 6=\ats, 7=\atnotClang, 8=\atnotpadyn, 9=\cscount, 10=\csClang, 11=\cspadyn
	}
	{\csvcoli & \csvcoliii & \csvcoliv & \csvcolv & \csvcolix & \csvcolx & \csvcolxi }% specify your coloumns here
    	\end{tabular}}
%     	}
	\caption {Table shows the quality of structural matching provided by our automated verify and test environment, 
	regarding call-sites and call-targets when compiling with optimization level O2. The label Clang miss 
	denotes elements not found in the data-set of the Clang/LLVM pass. The label tool miss denotes elements not found in the data-set of \textsc{TypeShield}.}
	\label{tbl:matchingquality}
\end{table}



\textbf{Call-sites.} While our structural matching of call-targets is rather simple, we have not so much luck regarding call-sites. While our tool can provide 
accurate addressing of call-sites within the binary, Clang/LLVM does not have such capabilities in its intermediate representation. Therefore we assume that 
the ordering of call-sites stays roughly the same within one function and that we exclude all functions, which report a different amount of call-sites in both datasets.
The table \ref{tbl:matchingquality} shows three data points regarding call-sites for the optimization levels O2:
\begin{itemize}
\item The number of comparable call-sites that are found in both datasets.
\item The number of call-sites that are discarded due to mismatch from the dataset of \textsc{TypeShield}, named Clang miss.
\item The number of call-sites that are discarded due to mismatch from the dataset of our Clang/LLVM pass, named tool miss.
\end{itemize}


Second, we look at call-sites and this is more problematic, as Clang/LLVM does not have a notion of instruction address in its IR, therefore we assume the ordering in a function is the same in both data-sets and when the call-site count is not the same for dyninst and Clang/padyn, we discard it. The are several reasons for mismatch: One is the tailcall optimization, which means that a call instructions at the end of a function are converted into jump instructions. Another one is call-site merging, which happens when a call to a function exists several times within a function and the compiler can merge the paths to this function.
Furthermore we already eliminated multiple compilations of the same source file during one test-target compilation (this would have skewed the results in the case of memcached).


\subsubsection{Precision Call-target / Call-site Classification (\textit{count})}
\label{subsection:typeshieldcountprecision}

For each experiment we measured two data points per testtarget, the number and ratio of perfect classifications and the number and ratio of problematic classifications, which in the case of calltargets refers to overestimations and in case of callsites refers to underestimations. The results are depicted in Table \ref{tbl:precisionCOUNT}.
\begin{table}[h!]
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & & \multicolumn{2}{c}{\bfseries Call-targets}\\
	
	\bfseries Target & \#  &  perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{csvs/classification_comp.sources_union_follow.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolii  &  \csvcolxii & \csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here

    	\end{tabular}

	\begin{tabular}{|c|c}%

	\toprule
	\multicolumn{2}{c}{\bfseries Call-sites}\\
	
	perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{csvs/classification_comp.sources_union_follow.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here

    	\end{tabular}
}
		\caption {The results for analysis using the union combination operator for the \textit{count} policy on the O2 optimization level.}
		\label{tbl:precisionCOUNT}
\end{table}~\\
\textbf{Experiment Setup (Call-targets)}
{Union combination operator with an $analyze$ function that follows into occurring direct calls.
}\\~\\
\textbf{Results (Call-targets)}{
The problem rate is under 0.01\%, as there are only two testtargets, that exhibit a problematic classification. The rate of perfect classification is in general over 80\% with mysql as an exception (73.85\%) resulting in a geometric mean of 86.86\%.
}\\~\\
\textbf{Experiment Setup (Call-sites)}
{ Union combination operator with an $analyze$ function that does not follow into occurring direct calls while relying on a backward inter-procedural analysis.
}\\~\\
\textbf{Results (Call-sites)} {
The problem rate is under 0.01\%, as there is only one testtarget, that exhibit a problematic classification. The rate of perfect classification is in general over 60\% with nginx (48.49\%) and node(56.34\%) as an exception resulting in a geometric mean of 71.97\%.}


\subsubsection{Precision Call-target / Call-site Classification (\textit{type})}
\label{subsection:typeshieldcountprecision}

For each experiment we measured two data points per testtarget, the number and ratio of perfect classifications and the number and ratio of problematic classifications, which in the case of calltargets refers to overestimations and in case of callsites refers to underestimations. The results are depicted in Table \ref{tbl:precisionTYPE}.
\begin{table}[h!]
\resizebox{0.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & & \multicolumn{2}{c}{\bfseries Call-targets}\\
	
	\bfseries Target & \#  &  perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{csvs/classification_comp2.type_exp6.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolii  &  \csvcolxii & \csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here

    	\end{tabular}

	\begin{tabular}{|c|c}%

	\toprule
	\multicolumn{2}{c}{\bfseries Call-sites}\\
	
	perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{csvs/classification_comp2.type_exp6.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here


    	\end{tabular}
}
		\caption {The results for analysis of the \textit{type} policy on the O2 optimization level.}
		\label{tbl:precisionTYPE}
\end{table}~\\
\textbf{Experiment Setup (Call-targets)}
{Union combination operator with an $analyze$ function that does follow into occurring direct calls  and a vertical merge that intersects all reads until the first write.
}\\~\\
\textbf{Results (Call-targets)}{
For half of the set, the problem rate is under 1\% and for the other half it is not above 10\%, resulting in a geomean of ?\%. The rate of perfect classification is in general over 80\% with mysql as an exception (73.85\%) resulting in a geometric mean of 86.86\%.
}\\~\\
\textbf{Experiment Setup (Call-sites)}
{ Union combination operator with an $analyze$ function that does not follow into occurring direct calls while relying on a backward inter-procedural analysis.
}\\~\\
\textbf{Results (Call-sites)} {
The problem rate is under 0.01\%, as there is only one testtarget, that exhibit a problematic classification. The rate of perfect classification is in general over 60\% with nginx (48.49\%) and node(56.34\%) as an exception resulting in a geometric mean of 71.97\%.}





\subsubsection{Precision Call-target Classification (\textit{type})}
\label{subsection:typeshieldprecision}
We are going to present a series of experiments and values to find the best possible combination operator for the call-target analysis in the \textit{type} policy.

\textbf{Experiment Setup.}
To choose the best possible combination operator for the call-target analysis in implementing the \textit{type} policy, we conducted three experiments based on the data of the Precision call-target Classification(\textit{count}) experiment and the proposed implementations for the \textit{type} policy:
\begin{itemize}
\item[exp1] union combination operator with an $analyze$ function that does follow into occurring direct calls and a vertical merge that only accepts the first change see Table \ref{tbl:CTdestinterexp12TYPE} for results.
\item[exp2] union combination operator with an $analyze$ function that does follow into occurring direct calls  and a vertical merge that unions all reads until the first write see Table \ref{tbl:CTdestinterexp12TYPE} for results.
\item[exp3] union combination operator with an $analyze$ function that does follow into occurring direct calls  and a vertical merge that intersects all reads until the first write see Table \ref{tbl:CTdestinterexp34TYPE} for results.
%\item[exp4] full union combination operator with an $analyze$ function that does not follow into occurring direct calls and a vertical merge that unions all reads until the first write  see Table \ref{tbl:CTdestinterexp34TYPE} for results.
\end{itemize}
For each possible version we measured two data points per test-target, the number and ratio of perfect classifications and the number and ratio of problematic classifications, which in this case refers to overestimations.

\textbf{Result.} The series exp2 shows the lowest problem rate of the three series. Regarding precision the values are as follows relatively equal:
\begin{itemize}
\item The series exp1 exhibits a geometric mean of 72.42\% for precision in O2.
\item The series exp2 exhibits a geometric mean of 72.25\% for precision in O2.
\item The series exp3 exhibits a geometric mean of 72.52\% for precision in O2. 
\end{itemize}
Due to exp2 exhibiting the lowest error value, we designate this setup as the best setup for analyzing the call-targets in the \textit{type} policy.

\begin{table}[h!]
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c}%

	\toprule
	 \multicolumn{1}{c}{\bfseries O2} & & \multicolumn{2}{c}{\bfseries exp1}\\
	
	\bfseries Target & \#  &  perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp1.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolii  &  \csvcolxii & \csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here

    	\end{tabular}

	\begin{tabular}{|c|c}%

	\toprule
    \multicolumn{2}{c}{\bfseries exp2}\\
	
	     perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp2.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here

    	\end{tabular}
}
		\caption {The results for call-target analysis for exp1 and exp2 of the \textit{type} policy throughout different optimizations.}
		\label{tbl:CTdestinterexp12TYPE}
\end{table}


\begin{table}[h!]
\centering
\resizebox{0.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & & \multicolumn{2}{c}{\bfseries exp3}\\
	
	\bfseries Target & \#  &  perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp3.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolii  &  \csvcolxii & \csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here

    	\end{tabular}
%
%	\begin{tabular}{|c|c}%
%
%	\toprule
%	\multicolumn{2}{c}{\bfseries exp4}\\
%	
%	perfect &  problem % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp4.O0.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp4.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp4.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_comp2.type_exp4.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolxiii (\csvcolxiv \%) & \csvcolxv (\csvcolxvi \%)}% specify your coloumns here
%
%
%    	\end{tabular}
}
		\caption {The results for call-target analysis for exp3 of the \textit{type} policy throughout different optimizations.}
		\label{tbl:CTdestinterexp34TYPE}
\end{table}



%\subsection{Precision Callsite Classification (\textit{type})}
%\label{subsection:typeshieldprecision}
%
%\paragraph{Experiment Setup}
%To choose the best possible combination operator for the callsite analysis in implementing the \textit{type} policy, we conducted four experiments based on the data of the two Precision Callsite Classification(\textit{count}) experiments:
%\begin{enumerate}
%\item[exp1] intersection combination operator that intersects when both paths are set with an $analyze$ function that does follow into occurring direct calls with backward inter-procedural analysis see Table \ref{tbl:CSexp12TYPE} for results.
%
%\item[exp2] intersection combination operator that unions when both paths are set with an $analyze$ function that does follow into occurring direct calls  with backward inter-procedural analysis  see Table \ref{tbl:CSexp12TYPE} for results.
%
%\item[exp3] union combination operator with an $analyze$ function that does not follow into occurring direct calls  with backward inter-procedural analysis  see Table \ref{tbl:CSexp34TYPE} for results.
%
%\item[exp4] general intersection operator with an $analyze$ function that does not follow into occurring direct calls  with backward inter-procedural analysis  see Table \ref{tbl:CSexp34TYPE} for results.
%\end{enumerate}
%For each possible version we measured two data points per testtarget, the number and ratio of perfect classifications and the number and ratio of problematic classifications, which in this case refers to overestimations.
%
%We are going to group our results into two classes based on the optimization level, completely unoptimized (O0) and optimized (O1, O2 and O3) as those two groups are highly different in the values they produce.
%
%\paragraph{Results for unoptimized targets}
%
%\paragraph{Results for optimized targets}
%
%
%\newpage
%\begin{table}[!htbp]
%\resizebox{\textwidth}{!}{
%	\begin{tabular}{l|c|c|c}%
%
%	\toprule
%	 \multicolumn{1}{c}{\bfseries O0} & & \multicolumn{2}{c}{\bfseries exp1}\\
%	
%	\bfseries Target & \#  &  perfect &  problem % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp1.O0.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{\bfseries O1} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp1.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{\bfseries O2}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp1.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{\bfseries O3}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_comp.type_exp1.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%    	\end{tabular}
%
%	\begin{tabular}{|c|c}%
%
%	\toprule
%    \multicolumn{2}{c}{\bfseries exp2}\\
%	
%	     perfect &  problem % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp2.O0.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%\multicolumn{1}{c}{}
%
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp2.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%	\multicolumn{1}{c}{}
%
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp2.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_comp.type_exp2.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%    	\end{tabular}
%}
%		\caption {The results for callsite analysis for exp1 and exp2 for the \textit{type} policy throughout different optimizations}
%		\label{tbl:CSexp12TYPE}
%\end{table}
%
%
%\begin{table}[!htbp]
%\resizebox{\textwidth}{!}{
%	\begin{tabular}{l|c|c|c}%
%
%	\toprule
%	\multicolumn{1}{c}{\bfseries O0} & & \multicolumn{2}{c}{\bfseries exp3}\\
%	
%	\bfseries Target & \#  &  perfect &  problem % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp3.O0.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{\bfseries O1} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp3.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{\bfseries O2}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp3.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{\bfseries O3}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_comp.type_exp3.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%    	\end{tabular}
%
%	\begin{tabular}{|c|c}%
%
%	\toprule
%	\multicolumn{2}{c}{\bfseries  exp4}\\
%	
%	perfect &  problem % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp4.O0.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp4.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp.type_exp4.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_comp.type_exp4.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%    	\end{tabular}
%}
%		\caption {The results for callsite analysis for exp3 and exp4 for the \textit{type} policy throughout different optimizations}
%		\label{tbl:CSexp34TYPE}
%\end{table}
\newpage
\subsubsection{Precision Call-site Classification (\textit{type})}
\label{subsection:typeshieldprecision}
We are going to present a series of experiments and values to find the best possible combination operator for the call-site analysis in the \textit{type} policy.

\textbf{Experiment Setup.}
To choose the best possible combination operator for the call-site analysis in implementing the \textit{type} policy, we conducted three  experiments based on the data of the two Precision call-site Classification(\textit{count}) experiments and the proposed implementations for the \textit{type} policy:
\begin{itemize}
\item[exp1] intersection combination operator that intersects when both paths are set with an $analyze$ function that does follow into occurring direct calls with backward inter-procedural analysis see Table \ref{tbl:CSexp12TYPE} for results.

\item[exp2] intersection combination operator that unions when both paths are set with an $analyze$ function that does follow into occurring direct calls  with backward inter-procedural analysis  see Table \ref{tbl:CSexp12TYPE} for results.

\item[exp3] union combination operator with an $analyze$ function that does not follow into occurring direct calls  with backward inter-procedural analysis  see Table \ref{tbl:CSexp34TYPE} for results.

%\item[exp4] general intersection operator with an $analyze$ function that does not follow into occurring direct calls  with backward inter-procedural analysis  see Table \ref{tbl:CSexp34TYPE} for results.
\end{itemize}
For each possible version we measured two data points per testtarget, the number and ratio of perfect classifications and the number and ratio of problematic classifications, which in this case refers to underestimations.

\textbf{Result.} The series exp3 easily holds the lowest rate of problematic classification and therefore we designate it the setup for a safe implementation of call-site analysis for the \textit{type} policy. The results for the series exp1 and the series exp2 are the same exhibiting a geometric mean of 57.30\% for precision in O2. Therefore it does not matter which of the two setups we choose for the precision implementation of call-site analysis for the \textit{type} policy.

\begin{table}[h!]
\centering
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c}%

	\toprule
	 \multicolumn{1}{c}{\bfseries O0} & & \multicolumn{2}{c}{\bfseries exp1}\\
	
	\bfseries Target & \#  &  perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp1.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here


    	\end{tabular}

	\begin{tabular}{|c|c}%

	\toprule
    \multicolumn{2}{c}{\bfseries exp2}\\
	
	     perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp2.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here

    	\end{tabular}
}
		\caption {The results for call-site analysis for exp1 and exp2 of the \textit{type} policy throughout different optimizations.}
		\label{tbl:CSexp12TYPE}
\end{table}


\begin{table}[h!]
\centering
\resizebox{0.5\textwidth}{!}{
	\begin{tabular}{l|c|c|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & & \multicolumn{2}{c}{\bfseries exp3}\\
	
	\bfseries Target & \#  &  perfect &  problem % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp3.O2.csv}{
		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
}
	{\csvcolii  &  \csvcoliii & \csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here


    	\end{tabular}

%	\begin{tabular}{|c|c}%
%
%	\toprule
%	\multicolumn{2}{c}{\bfseries  exp4}\\
%	
%	perfect &  problem % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp4.O0.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp4.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_comp2.type_exp4.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_comp2.type_exp4.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcoliv (\csvcolv \%) & \csvcolvi (\csvcolvii\%)}% specify your coloumns here
%
%
%    	\end{tabular}
}
		\caption {The results for enhanced call-site analysis for exp3 of the \textit{type} policy throughout different optimizations.}
		\label{tbl:CSexp34TYPE}
\end{table}
\newpage

%
%
%Efficiency
%
%
\subsection{RQ2: Effectiveness of \textsc{TypeShield}}
\label{section:typeshieldeffectiveness}
\todo[inline]{In this section we need just one or two Table similar to what TypeArmor contains, 
first we need to define the fields which make most sense.}

We are now going to evaluate the effectiveness of \textsc{TypeShield} leveraging the result of several experiment runs: First we are going to establish a baseline using the data 
collected from our Clang/LLVM pass, which are the theoretical limits our implementation can reach. Second we are going to evaluate the effectiveness of our \textit{count} 
policy and third we are going to evaluate the effectiveness of our \textit{type} policy. At last we are going to look at the effect our address taken analysis had on the results.

\subsubsection{Theoretical Limits.}
\label{subsection:theoreticallimit}
We explore the theoretical limits regarding the effectiveness of the \textit{count} and \textit{type} policies by relying on the collected ground truth data, which is essentially assume perfect classification.

\textbf{Experiment Setup} Based on the type information collected by our Clang/LLVM pass, we conducted two experiment series:
\begin{itemize}
\item We derived the \textit{count} schema using the ground truth and calculated the available number of call-targets for each call-site, see table \ref{tbl:policycomp} for results.
\item We derived the \textit{type} schema using the ground truth and calculated the available number of call-targets for each call-site, see table \ref{tbl:policycomp} for results.
\end{itemize}
For each series we collected three data points per test target, the average number of call-targets per call-site, the standard deviation $\sigma$ and the median.

\textbf{Results.}
\begin{itemize}
\item The theoretical limit of the \textit{count} schema has an overall geometric mean of 959 possible call-targets, which is 53.75\% of the geometric mean of total available 
call-targets.
\item The theoretical limit of the \textit{count} schema has an overall geometric mean of 823 possible call-targets, which is 46.10\% of the geometric mean of total available
call-targets.
\end{itemize}

When compared, the theoretical limit of the \textit{type} policy allows about 15\% less available call-targets in the geomean in O2 than the limit of the \textit{count} policy.

%
%\begin{table}[!htbp]
%\resizebox{\textwidth}{!}{
%	\begin{tabular}{l|c|rcl|rcl|rcl|rcl}%
%
%	\toprule
%	\multicolumn{1}{c}{\bfseries O0} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{6}{c}{\bfseries \textit{count}} & \multicolumn{6}{c}{\bfseries \textit{type}}\\
%	
%	\bfseries Target & &  \multicolumn{3}{c}{\bfseries measured} & \multicolumn{3}{c}{\bfseries limit} & \multicolumn{3}{c}{\bfseries measured} & \multicolumn{3}{c}{\bfseries limit} % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare.O0.csv}{
%		%1=opt,2=target,3=at,4=count,5=count sig,6=count*,7=count*sig,8=type,9=type sig,10=type*,11=type*sig
% }
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{\bfseries O1} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{\bfseries O2}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{\bfseries O3}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/policy_compare.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%
%    	\end{tabular}
%}
%		\caption {The results for comparing the different restriction policies throughout different optimizations}
%		\label{tbl:policycomp}
%\end{table}
%
%
%\begin{table}[!htbp]
%\resizebox{\textwidth}{!}{
%	\begin{tabular}{l|c|rcl|rcl|rcl|rcl}%
%
%	\toprule
%	\multicolumn{1}{c}{\bfseries O0} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{6}{c}{\bfseries \textit{count}} & \multicolumn{6}{c}{\bfseries \textit{type}}\\
%	
%	\bfseries Target & &  \multicolumn{3}{c}{\bfseries measured} & \multicolumn{3}{c}{\bfseries limit} & \multicolumn{3}{c}{\bfseries measured} & \multicolumn{3}{c}{\bfseries limit} % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare_at.O0.csv}{
%		%1=opt,2=target,3=at,4=count,5=count sig,6=count*,7=count*sig,8=type,9=type sig,10=type*,11=type*sig
% }
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%
%
%
%\multicolumn{1}{c}{\bfseries O1} 
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare_at.O1.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%	
%	
%\multicolumn{1}{c}{\bfseries O2}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare_at.O2.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%	
%
%\multicolumn{1}{c}{\bfseries O3}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/policy_compare_at.O3.csv}{
%		%1=opt,2=target,3=cs,4=cs args,5=perfect,6=cs args,7=problem,8 = cs non-void ,9=correct,10 = cs non-void, 11=problem,12 = ct, 13 = ct args, 14=perfect, 15 = ct args, 16=problem, 17 = ct void, 18=correct, 19=ct void, 20=problem
%}
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & $\pm$ & \csvcolvii & \csvcolviii & $\pm$ & \csvcolix & \csvcolx & $\pm$ & \csvcolxi}% specify your coloumns here
%
%    	\end{tabular}
%}
%		\caption {The results for comparing the different restriction policies restricted using an address taken analysis throughout different optimizations}
%		\label{tbl:policycompat}
%\end{table}

\begin{table}[h!]
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|rcl|c|rcl|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O0} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{4}{c}{\bfseries \textit{count}*} & \multicolumn{4}{c}{\bfseries \textit{type}*}\\
	
	\bfseries Target & & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median  % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare.O0.csv}{
	%1=opt,2=target,3=at,4=count safe avg,5=count safe sig,6=count safe median,7=count prec avg,8=count prec sig,9=count prec median,10=count* avg,11=count* sig,12=count* median,13=type safe avg,14=type safe sig,15=type safe median,16=type prec avg,17=type prec sig,18=type prec median,19=type* avg,20=type* sig,21=type* median
 }
	{\csvcolii  &  \csvcoliii & \csvcolx & $\pm$ & \csvcolxi & \csvcolxii & \csvcolxix & $\pm$ & \csvcolxx& \csvcolxxi}% specify your coloumns here


    	\end{tabular}
}
		\caption {The results of comparing theoretical limits for the different restriction policies throughout different optimizations.}
		\label{tbl:policycomp}
\end{table}

\newpage
\subsubsection{\textsc{TypeShield} implementation of the \textit{count} policy}
\label{subsection:typeshieldvslimitcount}
We explore the effectiveness of our safe and precise versions for the \textit{count} policy implementation.

\textbf{Experiment Setup.} We setup our two experiment series based on our previous evaluations regarding the classification precision for the \textit{count} policy.
\begin{itemize}
\item For the safe version, we chose the union combination operator, with $analyse$ that follows into occurring direct calls to 
calculate the call-target invariant. For the call-site invariant, we chose the union operator that does not follow into occurring direct calls with backwards inter-procedural analysis.  See table \ref{tbl:policycompcount} for results. 
\item For the precise version, we chose the union combination operator, with $analyse$ that follows into occurring direct calls to calculate the call-target invariant. For the 
call-site invariant, we chose the intersection operator that follows into occurring direct calls with backwards inter-procedural analysis. See table \ref{tbl:policycompcount} 
for results. 
\end{itemize}
For each series we collected three data points per test target, the average number of call-targets per call-site, the standard deviation $\sigma$ and the median.

\textbf{Results.}
\begin{itemize}
\item The average number of available targets provided by the safe implementation of the \textit{count} schema has an overall geometric mean of  1283 possible call-targets, 
which is 71.87\% of the geometric mean of total available call-targets. This is 33.78\% more than the theoretical limit of available call-targets per call-site.
\item The average number of available targets provided by the precise implementation of the \textit{count} schema has an overall geometric mean of  1030 possible call-targets, 
which is 57.70\% of the geometric mean of total available call-targets. This is 7.40\% more than the theoretical limit of available call-targets per call-site.
\end{itemize}

When compared, the precise implementation of of the \textit{count} policy allows about 20\% less available call-targets in the geomean in O2 than the safe implementation of 
the \textit{count} policy.


\begin{table}[h!]
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|rcl|c|rcl|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{4}{c}{\bfseries \textit{count} safe} & \multicolumn{4}{c}{\bfseries \textit{count} prec}\\
	
	\bfseries Target & & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median  % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare.O2.csv}{
	%1=opt,2=target,3=at,4=count safe avg,5=count safe sig,6=count safe median,7=count prec avg,8=count prec sig,9=count prec median,10=count* avg,11=count* sig,12=count* median,13=type safe avg,14=type safe sig,15=type safe median,16=type prec avg,17=type prec sig,18=type prec median,19=type* avg,20=type* sig,21=type* median
 }
	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & \csvcolvii & $\pm$ & \csvcolviii& \csvcolix}% specify your coloumns here

    	\end{tabular}
}
		\caption {The results of comparing \textit{count} safe and precision implementation throughout different optimizations.}
		\label{tbl:policycompcount}
\end{table}

\newpage

\subsubsection{\textsc{TypeShield} implementation of the \textit{type} policy}
\label{subsection:typeshieldvslimitcount}
We explore the effectiveness of our safe and precise versions for the \textit{type} policy implementation.

\textbf{Experiment Setup.} We setup our two experiment series based on our previous evaluations regarding the classification precision for the \textit{type} policy.
\begin{itemize}
\item For the safe version, we chose the union combination operator with an $analyze$ function that does follow into occurring direct calls  and a vertical merge that unions all reads until the first write to calculate the call-target invariant. For the call-site invariant, we chose the union combination operator with an $analyze$ function that does not follow into occurring direct calls  with backward inter-procedural analysis.  See table \ref{tbl:policycomptype} for results. 
\item For the precise version, we chose union combination operator with an $analyze$ function that does follow into occurring direct calls  and a vertical merge that unions all reads until the first write to calculate the call-target invariant. For the call-site invariant, we chose the intersection combination operator that intersects when both paths are set with an $analyze$ function that does follow into occurring direct calls with backward inter-procedural analysis. See table \ref{tbl:policycomptype} for results. 
\end{itemize}
For each series we collected three data points per test target, the average number of call-targets per call-site, the standard deviation $\sigma$ and the median.

\textbf{Results.}
\begin{itemize}
\item The average number of available targets provided by the safe implementation of the \textit{type} schema has an overall geometric mean of  1144 possible call-targets, which is 64.08\% of the geometric mean of total available call-targets. This is 39.00\% more than the theoretical limit of available call-targets per call-site.
\item The average number of available targets provided by the precise implementation of the \textit{type} schema has an overall geometric mean of  907 possible call-targets, which is 50.81\% of the geometric mean of total available call-targets. This is 10.20\% more than the theoretical limit of available call-targets per call-site
\end{itemize}

When compared, the precise implementation of of the \textit{count} policy allows about 21\% less available call-targets in the geomean in O2 than the safe implementation of the \textit{count} policy.


\begin{table}[h!]
\resizebox{.5\textwidth}{!}{
	\begin{tabular}{l|c|rcl|c|rcl|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{4}{c}{\bfseries \textit{type} safe} & \multicolumn{4}{c}{\bfseries \textit{type} prec}\\
	
	\bfseries Target & & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median  % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare.O2.csv}{
	%1=opt,2=target,3=at,4=count safe avg,5=count safe sig,6=count safe median,7=count prec avg,8=count prec sig,9=count prec median,10=count* avg,11=count* sig,12=count* median,13=type safe avg,14=type safe sig,15=type safe median,16=type prec avg,17=type prec sig,18=type prec median,19=type* avg,20=type* sig,21=type* median
 }
	{\csvcolii  &  \csvcoliii & \csvcolxiii & $\pm$ & \csvcolxiv & \csvcolxv & \csvcolxvi & $\pm$ & \csvcolxvii& \csvcolxviii}% specify your coloumns here


    	\end{tabular}
}
		\caption {The results of comparing \textit{type} safe and precision implementation throughout different optimizations.}
		\label{tbl:policycomptype}
\end{table}

\newpage


\subsubsection{Effect of our AddressTaken Analysis}
\label{subsection:effectivenessaddresstaken}
We are providing experiment results and an evaluation regarding the impact of our address taken analysis on the theoretical limits and our various policy implementations, 
namely the safe and precise versions of the \textit{count} and \textit{type} policies.

\textbf{Experiment Setup.} We conducted the same three experiments as before but with the initial set of call-targets filtered by our implementation of address taken analysis:
\begin{itemize}
\item We setup the same experiment regarding theoretical limits as described in subsection \ref{subsection:theoreticallimit} but with restricting the possible call-targets 
to only address taken functions. The results are presented in table \ref{tbl:policycompat}.
\item We setup the same experiment regarding the \textit{count} policy as described in subsection \ref{subsection:theoreticallimit} but with restricting the possible call-targets
to only address taken functions. The results are presented in table \ref{tbl:policycompatcount}.
\item We setup the same experiment regarding the \textit{type} policy as described as in subsection \ref{subsection:theoreticallimit} but with restricting the possible call-targets
to only address taken functions. The results are presented in table \ref{tbl:policycompattype}.
\end{itemize}
For each series we collected three data points per test target, the average number of call-targets per call-site, the standard deviation $\sigma$ and the median.

\textbf{Results.} First of all we observed an overall reduction of the geometric mean of overall available call-targets to 64\% before our policies were applied. Notable outliers
are memcached, which had a 90\% reduction of available call-targets and vsftpd, which even achieved a 97\% reduction in available call-targets.
\begin{itemize}
\item The theoretical available targets were overall reduced to 25.96\% in the \textit{count} policy case  (geometric mean of 249 in O2) and to 27.27\% in the \textit{type} 
policy case  (geometric mean of 224 in O2). The difference between their geometric means shrank from about 15\% to about 10\%.
\item The average targets provided by the safe and the precise implementation of the \textit{count} policy were reduced to 25.33\% (geometric mean of 325 in O2) and 25.92\% 
(geometric mean of 267) respectively. The difference between their geometric means shrank from about 20\% to about 18\%.
\item The average targets provided by the safe and the precise implementation of the \textit{count} policy were reduced to 26.13\% (geometric mean of 299 in O2) and 26.79\% 
(geometric mean of 243) respectively. The difference between their geometric means shrank from about 20\% to about 18\%.
\end{itemize}

When comparing the precision focused implementations of our \textit{type} policy and our \textit{count}, we observe that the difference between them shrank to about 9\% when 
comparing their geometric means.

Overall we were able to reduce the number of available call-targets per call-site from 1785 to 243 using our precision focused implementation of the \textit{type} policy,
which is an overall reduction to 13.61\%.

\begin{table*}[h!]
\resizebox{\textwidth}{!}{
	\begin{tabular}{l|c|rcl|c|rcl|c|rcl|c|rcl|c}%

	\toprule
	\multicolumn{1}{c}{\bfseries O2} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{4}{c}{\bfseries \textit{count}*} & \multicolumn{4}{c}{\bfseries \textit{count}} & \multicolumn{4}{c}{\bfseries \textit{type}*} & \multicolumn{4}{c}{\bfseries \textit{type}}\\
	
	\bfseries Target && \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median  % specify table head
	\\\midrule
	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare_at.O2.csv}{
	%1=opt,2=target,3=at,4=count safe avg,5=count safe sig,6=count safe median,7=count prec avg,8=count prec sig,9=count prec median,10=count* avg,11=count* sig,12=count* median,13=type safe avg,14=type safe sig,15=type safe median,16=type prec avg,17=type prec sig,18=type prec median,19=type* avg,20=type* sig,21=type* median
 }
	{\csvcolii  &  \csvcoliii & \csvcolx & $\pm$ & \csvcolxi & \csvcolxii & \csvcolvii & $\pm$ & \csvcolviii& \csvcolix& \csvcolxix & $\pm$ & \csvcolxx& \csvcolxxi & \csvcolxvi & $\pm$ & \csvcolxvii& \csvcolxviii }% specify your coloumns here

    	\end{tabular}

}
		\caption {The results of comparing our implementation results with the theoretical limits for the different restriction policies combined with an an address taken analysis for optimization level O2.}
		\label{tbl:policycompat}
\end{table*}


%\begin{table}[h!]
%\resizebox{.4\textwidth}{!}{
%	\begin{tabular}{l|c|rcl|c|rcl|c}%
%
%	\toprule
%	\multicolumn{1}{c}{\bfseries O2} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{4}{c}{\bfseries \textit{count} safe} & \multicolumn{4}{c}{\bfseries \textit{count} prec}\\
%	
%	\bfseries Target && \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median  % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare_at.O2.csv}{
%	%1=opt,2=target,3=at,4=count safe avg,5=count safe sig,6=count safe median,7=count prec avg,8=count prec sig,9=count prec median,10=count* avg,11=count* sig,12=count* median,13=type safe avg,14=type safe sig,15=type safe median,16=type prec avg,17=type prec sig,18=type prec median,19=type* avg,20=type* sig,21=type* median
% }
%	{\csvcolii  &  \csvcoliii & \csvcoliv & $\pm$ & \csvcolv & \csvcolvi & \csvcolvii & $\pm$ & \csvcolviii& \csvcolix}% specify your coloumns here
%
%    	\end{tabular}
%}
%		\caption {The results of comparing \textit{count} safe and precision implementation restricted using an address taken analysis throughout different optimizations.}
%		\label{tbl:policycompatcount}
%\end{table}
%
%\begin{table}[h!]
%\resizebox{.4\textwidth}{!}{
%	\begin{tabular}{l|c|rcl|c|rcl|c}%
%
%	\toprule
%	\multicolumn{1}{c}{\bfseries O2} & \multicolumn{1}{c}{\bfseries AT} & \multicolumn{4}{c}{\bfseries \textit{type} safe} & \multicolumn{4}{c}{\bfseries \textit{type} prec}\\
%	
%	\bfseries Target && \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median & \multicolumn{3}{c}{ limit (mean $\pm$ $\sigma$)} & median  % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/policy_compare_at.O2.csv}{
%	%1=opt,2=target,3=at,4=count safe avg,5=count safe sig,6=count safe median,7=count prec avg,8=count prec sig,9=count prec median,10=count* avg,11=count* sig,12=count* median,13=type safe avg,14=type safe sig,15=type safe median,16=type prec avg,17=type prec sig,18=type prec median,19=type* avg,20=type* sig,21=type* median
% }
%	{\csvcolii  &  \csvcoliii & \csvcolxiii & $\pm$ & \csvcolxiv & \csvcolxv & \csvcolxvi & $\pm$ & \csvcolxvii& \csvcolxviii}% specify your coloumns here
%
%    	\end{tabular}
%}
%		\caption {The results of comparing \textit{type} safe and precision implementation restricted using an address taken analysis throughout different optimizations.}
%		\label{tbl:policycompattype}
%\end{table}

%
%\newpage
%\section{Security Analysis of \textsc{TypeShield}}
%\label{section:typeshieldsecurityanalysis}
%
%In this section, we discuss how effective \textsc{TypeShield} is 
%stopping advance code-reuse attacks (CRAs).
%Patching Policies
%Two types of diagrams. Table 5 from TypeArmor and a CDF to compare param count and param type. (baseline)
%here we put the CDF graphs from. There is no accurate security metrics to asses the security level of the enforced policy.
%
%
%
%\begin{table}
%\centering
%\resizebox{0.8\textwidth}{!}{
%	\begin{tabular}{l|c|c|c|c|c|c|c|c|c}%
%	\toprule
%	\multicolumn{1}{c}{\bfseries O0} & \multicolumn{1}{c}{} & \multicolumn{8}{|c}{ {\bfseries parameters}} \\
%	\bfseries Target & \bfseries \#CS & \bfseries -x & \bfseries +0 & \bfseries +1 & \bfseries +2 & \bfseries +3 & \bfseries +4 & \bfseries +5 & \bfseries +6 % specify table head
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_cs.O0.csv}{
%		%1=target,2=opt,3=cs,4=problems,5=+0,6=+1,7=+2,8=+3,9=+4,10=+5,11=+6,12=non-void-ok,13=non-void-problem
%	}
%	{\csvcoli & \csvcoliii & \csvcoliv & \csvcolv & \csvcolvi & \csvcolvii & \csvcolviii & \csvcolix & \csvcolx & \csvcolxi }% specify your coloumns here
%
%	\multicolumn{1}{c}{\bfseries O1}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_cs.O1.csv}{
%		%1=target,2=opt,3=cs,4=problems,5=+0,6=+1,7=+2,8=+3,9=+4,10=+5,11=+6,12=non-void-ok,13=non-void-problem
%	}
%	{\csvcoli & \csvcoliii & \csvcoliv & \csvcolv & \csvcolvi & \csvcolvii & \csvcolviii & \csvcolix & \csvcolx & \csvcolxi}% specify your coloumns here
%
%	\multicolumn{1}{c}{\bfseries O2}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\midrule]{../MA_Pictures/classification_cs.O2.csv}{
%		%1=target,2=opt,3=cs,4=problems,5=+0,6=+1,7=+2,8=+3,9=+4,10=+5,11=+6,12=non-void-ok,13=non-void-problem
%	}
%	{\csvcoli & \csvcoliii & \csvcoliv & \csvcolv & \csvcolvi & \csvcolvii & \csvcolviii & \csvcolix & \csvcolx & \csvcolxi}% specify your coloumns here
%
%	\multicolumn{1}{c}{\bfseries O3}
%	\\\midrule
%	\csvreader[ late after line=\\, late after last line=\\\bottomrule]{../MA_Pictures/classification_cs.O3.csv}{
%		%1=target,2=opt,3=cs,4=problems,5=+0,6=+1,7=+2,8=+3,9=+4,10=+5,11=+6,12=non-void-ok,13=non-void-problem
%	}
%	{\csvcoli & \csvcoliii & \csvcoliv & \csvcolv & \csvcolvi & \csvcolvii & \csvcolviii & \csvcolix & \csvcolx & \csvcolxi}% specify your coloumns here
%
%
%    	\end{tabular}
%	}
%		\caption {Table shows the overestimation of the parameter count in matched callsites occurring in our precision focussed implementation of the \textit{count} policy, with -x denoting problematic callsites, when compiling with optimization levels O0 through O3}
%	\label{tbl:baselinecs}
%\end{table}
%
%\begin{figure}
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/vsftpd.pdf}
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/lighttpd.pdf}\\
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/memcached.pdf}
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/mysql.pdf}\\
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/nginx.pdf}
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/node.pdf}\\
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/postgresql.pdf}
%\includegraphics[width=0.5\textwidth]{../MA_Pictures/proftpd.pdf}
%\end{figure}
%


\subsection{RQ3: Runtime Performance Overhead}
\label{section:typeshieldoverheadperformance}
\todo[inline]{In this section we need one or two Table similar to what TypeArmor contains, first we need to define the fields which make most sense.}
Here we measure how much performance overhead the instrumentation incurs.
Here we measure with the same SPEC2006 programs that was used in the TypeArmor paper.
spec 2006.
\todo[inline]{add a binary patch that does not crash none of the programs from SPEC2006.}
\todo[inline]{need a table with all the results for each of the SPEC2006 programs and a bar diagram}

\subsection{RQ4: Instrumentation Overhead}
\label{section:typeshieldoverheadinstrumentation}
\todo[inline]{here we need a bar chart, see TypeArmor paper.}
Here we measure how much the binaries increased in size after the instrumentation was added to the binaries.
\todo[inline]{Measure the size (in bytes) of the SPEC2006 testes in RQ3 before and after adding all the patches}


\subsection{RQ5: Security Level of \textsc{TypeShield}}
\label{section:mitiagtion}
\todo[inline]{here we need a a CDF figure, see the TypeAmor paper w.r.t. security analysis in the evaluation. The buckets have to be defined first, reason about if they make sense!}
We look at our implementation conceptually and assess qualitatievly whether our implementation can interfere with various classes of attacks. 
\todo[inline]{see the TypeAmor paper w.r.t. security analysis in the evaluation, a CDF figure is here required.}

\subsection{RQ6: Add another evaluation dimention we did not think off, maybe ``RQ6: TypeShield Deployments" (if it is easy or hard to deploy our tool in
comparison with TypeArmor.)}
\label{section:mitiagtion}
\todo[inline]{need to define first the question.}

% \subsection{COOP}
% \label{Effectiveness against COOP}
% 
% \subsubsection{COOP Extensions}
% \label{COOP Extensions}
% 
% \subsubsection{Pure Data-only Attacks}
% \label{Pure Data-only Attacks}
