I Structural Matching:
    a) Problem: multiple versions of the same name (violation of the one name rule in C/C++)
        - Reason: multiple binaries (executables, libraries, ...)
        - Solution(s):
            i) single binary compilation (not supported by every build script!)
            ii) lto pass for clang (probably possible, but not sure)
            iii) both of the above to exchange when one is not possible (script !)
    *This problem needs to be addressed for sure. You should try the apporoaches mentioned above.
    *Interestinglt the TA paper does not loose any word on this issue.

    b) Documentation (!)
        - clang-augment
        - clang-collect
        - python-parse
        - changes due to lto (?)
    *Not sure what you really mean here. Be more specific.
    *If you mean code documentation than this is fine with me.

II Test/Data Collection Environment
    a) Slightly refactor to allow easier usage of:
        - specifying output
        - inclusion of test targets
        - general cleanup
    *Makes sense.

    b) Documentation (!)
        - what is available (python/bash)
        - how does one use it
    *Makes sense.

III Patching
    a) Some SPEC2006 programms crash when using BPatch_dynamicTarget
        - Reason: To be determined
        - To Exclude:
            i) Dyninst Patching itself (however that *should* not be the case, as other papers have used that)
            ii) function anotation (however that also *should* not be the case, because it also crashed without)
            iii) alignment issue, due to the code (?), which is therefore defective and the compiler
                can do what it wants, hence Dyninst has problems with the binary that are not obvious
        - Solution(s):
            i) patch in an ASM function that performs the check based on memory lookuptables or
                similar (possible performance impact)
    * Why no use PSI?, see http://seclab.cs.sunysb.edu/seclab/pubs/vee14.pdf
      Code of PSI is also available. I suggested this solution some time ago.
      Also posting this issue on the Dyninst forum could help a lot. This puts presure on the DynInst implementaton team and
      they should provide some answer though.

    b) Possible Crash of the patching when applying on node
        - Reason: possibly a memory leak in DynamoRIO or Dyninst
        - Solution(s):
            i) None until the 
    *Hm, maybe the patch is not intended to be used like that. Also, other approaches have to be inspected.
    *Have no clue neither.
    *Maybe the size in bytes of the patch is inportant and I strongly suggest to have a look at PSI.
            
    b) Documentation (!)
        - Patching Schema
    *This is very important since it is poorly documented in the paper. I think we do not have anything at all here.
        
IV Classification
    a) Find Problems of misclassification (under and overapprox !)
    *makes sense.

    b) Extend via respecting return-values
    *We could benefit a lot from this. It would extend the scope of our paper and we could 100% compare with TA.

    c) Extend via vcalls vs non-vcalls
    * Filltering is an important issue and it makes sense to have a filtering mechanism in place.
    * By fliping an internat code flag one could include or exclude this from the analysis. 

V Paper
    a) Section (VCalls)
        - tatsächlichen Zusammenhang zum Rest des papiers herstellen oder zu den entsprechenden
            anderen sektionen hinzufügen
    *Hm, not sure what you realy mean here. Where would you add this section? What do you have in Mind exactly?
    *This makes sense to me after we have the knob (flag) for excluding or including vcals into our analysis. See point above *flipping*.

    b) Section (Overview)
        - Generell überarbeiten
        - Auf das TA paper verweisen 
    *makes sense, has to be done at the end or when the most of the implementation work is done.

    c) Section (Design)
        - Algorithmen *möglicherweise* zusammenfügen (?)
    *not sure why. More stronly I would like to have the two algs. more detailed and more emphasis on the differences between them.
    *Currently they are very similar our paper. Focus more on their differences makes more sense. Also, use inside latex algorithm, algorithmic    whould help to make the algoritms look beter.
        - Die beschreibung der algorithmen auf maximal 2 Seiten zusammenfassen
    *Rather not reduce the size but go more on the differences between our algs and the ones used in TA and argue why ours are better.
        - Spezialfälle genauer beschreiben und *alle* soweit möglich aufzählen
    *makes a lot of sense.
        - Auf das TA paper verweisen
    *makes a lot of sense. Also, I would like to enforce the differences of our algorithms with respect to that of the ones
    used in TA tool.

    d) Section (Implementation)
        - *Möglicherweise* zuviel Text -> Reduzieren
    * could be done. Not a real priority for now.

    e) Section (Evaluation)
        - Structural Matching größe der analyse verringern
        * what do you mean here? Why reduce the size of the analysis? How can we benefit from this?

        - Patching RQs mit daten füllen (man kann nicht allzuviel zu performance und binarygröße
            sagen, ausser die diagramme Zeigen, beschreiben und 2 sätze über den *möglichen* Grund verlieren.
        *I fully agree with you. But first we need to have our own diagrams here in place and remove the stubs.
        *Also, I am quite amazed about how big a binary could can get after patching. Interestingly the TA paper does not
        *loose a word about this issue.
        *Also, I would like to see how the patched servers perform under stress by simulating a load on them afther patching in order
        *to see how patching afects the runtime of these progs.

        - Generell den Unterschied zwischen Effektivität und Security einmal bitte fest für uns
            definieren (aktuell nicht vorhanden)
        *makes sense. This is not a trivial taks for now. First I would emulate the TA paper approach of addressing this.
        *Also there is another RQ in the paper which addresses this issue. The main focus is there on the CDF figures and a buket bar graph, currently this is missing.

            das einzige sinvolle was mir einfällt, was man machen kann ist, die effektivität im bezug
            auf reduktion der callsite - calltarget paare zu definieren und uns dann in der security
            analysis darauf zur allgemeinen sicherheit zu beziehen
        * makes sense. Also we are on the safe side if we adopt the way how the TA paper addresses this issue.

            was wir nicht machen können ist das CDF zur security Analysis einfach so zu ziehen
        *fully agree. There are just for now naivelly moved there in order to have a separation.

            aktuell ist das ganze einfach nur diagramme zusammennehmen, weil das andere paper
            diese hat und nicht weil wir diese benötigen um ein argument darzustellen.
            ein CDF ist zb dafür da, dass wir zeigen können, wie weit die reduktion über verschiede
            percentiles geht, das machen wir aber aktuell nicht (das diagramm generieren kann
            vllt aktuell sogar verbuggt sein)

            Security Analysis würde bedeuten, dass wir uns tatsächliche Angriffe oder zumindest
            angriffsklassen ansehen und dann erklären, ob wir die aufhalten können und warum/warum nicht
       *maybe a table could help in which we present all variations of COOP which we can stop with TypeShield and other attacks which are based on violations of forward indirect edges in binaries.    There should be a bunch of such attacks. Basically, all attacks which pass some parameters whithout respecting the calling convention are canditates for this table.

            (haben ja verschiedene Angriffsmöglichkeiten, die wir uns ansehen können, COOP ist ja
                nur eine von vielen)
       *exactly. Bassically this new section whould be just a simple fact based argumentation why our approach can mitigate, X, Y and Z attacks.
       
        - Hier würde ich ausserdem noch was bezüglich theoretischer anzahl an buckets vs
            tatsächlicher anzahl an buckets bringen wollen
       *makes sense, ando alos maybe adress some discrepancies of buket usage by type armor which don't make sense at all but are still used in the paper.
                
        f) Sections (Discussion), (Future Work) and (Conclusion)
            TODO
       *adapt those accordingly after the other sections from above are in place.
